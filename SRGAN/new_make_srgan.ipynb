{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Dense, Add, Reshape, Permute\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ratio = 4\n",
    "LR_shape = np.array([120, 160, 3])\n",
    "g_weight_name = \"g_weight_01.h5\"\n",
    "d_weight_name = \"d_weight_01.h5\"\n",
    "\n",
    "L_h, L_w, c = LR_shape\n",
    "H_h = L_h * ratio\n",
    "H_w = L_w * ratio\n",
    "HR_shape = np.array([H_h, H_w, c])\n",
    "\n",
    "optimizer = Adam()\n",
    "\n",
    "\n",
    "        \n",
    "def pixel_shuffle(in_map, h, w, c = channels):\n",
    "    x = Reshape((h, w, 2, 2, c))(in_map)\n",
    "    x = Permute((3, 1, 4, 2, 5))(x)\n",
    "    out_map = Reshape((2 * h, 2 * w, c))(x)\n",
    "    return Model(in_map, out_map)\n",
    "\n",
    "def upsampling(in_map, h, w, c):\n",
    "    x = Conv2D(filters = 4 * c, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     padding = \"same\")(in_map)\n",
    "    x = pixel_shuffle(x, h, w, c)\n",
    "    out_map = PReLU()(x)\n",
    "    return Model(in_map, out_map)\n",
    "\n",
    "def residual_block(in_map):\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(in_map)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out_map = Add()([x, in_map])\n",
    "    return out_map\n",
    "\n",
    "def d_block(in_map, filters, kernel_size, strides, padding):\n",
    "    d = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)(in_map)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    return d\n",
    "\n",
    "def denormalize(img):\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def save_images(epoch, hr_img, lr_img, sr_img):\n",
    "    hr_img = denormalize(hr_img)\n",
    "    lr_img = denormalize(lr_img)\n",
    "    sr_img = denormalize(sr_img)\n",
    "    \n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_HRimage.png\", hr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_LRimage.png\", lr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_SRimage.png\", sr_img)\n",
    "\n",
    "    \n",
    "def psnr_calc(img1: np.ndarray, img2: np.ndarray):\n",
    "    def convert(img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    def extract_y(image: np.ndarray) -> np.ndarray:\n",
    "        if image.ndim == 2:\n",
    "            return image\n",
    "        image = image.astype(np.int32)\n",
    "        return ((image[:, :, 2] * 65.481 / 255.\n",
    "                  + image[:, :, 1] * 128.553 / 255.\n",
    "                  + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n",
    "\n",
    "\n",
    "    def psnr(img1, img2):\n",
    "        mse = np.mean((img1 - img2) ** 2)\n",
    "        if mse == 0:\n",
    "            return 100\n",
    "        PIXEL_MAX = 255.0\n",
    "        return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n",
    "\n",
    "    img1_conv=convert(img1)\n",
    "    img2_conv=convert(img2)\n",
    "\n",
    "    # BGR -> YCrCb\n",
    "    # 画像はcv2.imreadで読まれている前提 [0, 255]\n",
    "    y1 = extract_y(img1_conv)\n",
    "    y2 = extract_y(img2_conv)\n",
    "    # 周囲のcropping\n",
    "    # assert y1.shape == y2.shape\n",
    "    h, w = y1.shape\n",
    "    cr = ratio\n",
    "    cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "    cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "\n",
    "    # psnr\n",
    "    psnr_val = psnr(cropped_y1, cropped_y2)\n",
    "    return psnr_val\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    middle = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(input_img)\n",
    "    middle = PReLU()(middle)\n",
    "    \n",
    "    g = residual_block(middle)\n",
    "    for _ in range(4):\n",
    "        g = residual_block(g)\n",
    "\n",
    "    g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = Add()([g, middle])\n",
    "\n",
    "    n = ratio\n",
    "    i = 1\n",
    "    while(n % 2 == 0):\n",
    "        g = upsampling(g, L_h * i, L_w * i, c)\n",
    "        i = i * 2\n",
    "        n = n // 2\n",
    "\n",
    "    output_img = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(g)\n",
    "\n",
    "    return Model(input_img, output_img)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = Input(shape = HR_shape)\n",
    "    \n",
    "    d = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(input_img)\n",
    "    d = d_block(d, filters = 64, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = Dense(1024)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    output_img = Dense(1, activation = \"sigmoid\")(d)\n",
    "\n",
    "    return Model(input_img, output_img)\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def build_vgg():\n",
    "    vgg = VGG19(include_top = False)\n",
    "    return Model(vgg.input, vgg.layers[9].output)\n",
    "    \n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def combined(generator, discriminator, vgg):\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    fake_img = generator(input_img)\n",
    "    \n",
    "    validity = discriminator(fake_img)\n",
    "    features = vgg(fake_img)\n",
    "    \n",
    "    return Model(input_img, [validity, features])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs_checkpoint = []\n",
    "psnr = []\n",
    "\n",
    "def train(epochs, batch_size, interval):\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        real_imgs, lr_imgs = load_data(batch_size)\n",
    "        fake_imgs = generator.predict(lr_imgs)\n",
    "        \n",
    "        #Dの訓練\n",
    "        d_loss_real = self.discriminator.train_on_batch(real_imgs, valid)\n",
    "        d_loss_fake = self.discriminator.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        #Gの訓練\n",
    "        vgg_features = vgg.predict(real_imgs)\n",
    "        g_loss = srgan.train_on_batch(lr_imgs, [real, vgg_features])\n",
    "        \n",
    "        time = datetime.datetime.now() - start_time\n",
    "        print(\"%d time: %s\" % (epoch, time))\n",
    "        \n",
    "        if epoch+1 % interval == 0:\n",
    "            losses.append((d_loss, g_loss))\n",
    "            epochs_checkpoint.append(epoch+1)\n",
    "            save_images(epoch, real_imgs[0], lr_imgs[0], fake_imgs[0])\n",
    "            psnr.append(calc_psnr(real_imgs[0], fake_imgs[0]))\n",
    "            \n",
    "    generator.save_weights(g_weight_name)\n",
    "    discriminator.save_weights(d_weight_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/gan/lib/python3.6/site-packages/keras/engine/network.py:190: UserWarning: Model inputs must come from `keras.layers.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to your model was not an Input tensor, it was generated by layer conv2d_280.\n",
      "Note that input tensors are instantiated via `tensor = keras.layers.Input(shape)`.\n",
      "The tensor that caused the issue was: conv2d_280/BiasAdd:0\n",
      "  str(x.name))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_28:0\", shape=(None, 120, 160, 3), dtype=float32) at layer \"input_28\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-c60d64cccb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                       metrics = [\"accuracy\"])\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msrgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-21998714ae1c>\u001b[0m in \u001b[0;36mbuild_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_h\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-74e0b8acbaf8>\u001b[0m in \u001b[0;36mupsampling\u001b[0;34m(in_map, h, w, c)\u001b[0m\n\u001b[1;32m     35\u001b[0m                      \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                      padding = \"same\")(in_map)\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mout_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-74e0b8acbaf8>\u001b[0m in \u001b[0;36mpixel_shuffle\u001b[0;34m(in_map, h, w, c)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mout_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/gan/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/gan/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/gan/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 241\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/gan/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m                                          \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                                          \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1512\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_28:0\", shape=(None, 120, 160, 3), dtype=float32) at layer \"input_28\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "#------------------------------------\n",
    "# メインプログラム\n",
    "#------------------------------------\n",
    "\n",
    "#Discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss = \"mse\",\n",
    "                      optimizer = optimizer,\n",
    "                      metrics = [\"accuracy\"])\n",
    "#Generator\n",
    "generator = build_generator()\n",
    "discriminator.trainable = False\n",
    "srgan = combined(generator, discriminator)\n",
    "srgan.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs = 1000, batch_size = 1, interval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_2/Sigmoid:0\", shape=(?, 30, 40, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "D = Discriminator(480, 640, 3)\n",
    "img = Image.open(\"../../images/train/image_1.png\")\n",
    "img = np.array(img)\n",
    "valid = D.discriminate(img)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
