{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Dense, Add, Reshape, Permute, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG19\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ratio = 4\n",
    "LR_shape = (120, 160, 3)\n",
    "g_weight_name = \"g_weight_01.h5\"\n",
    "d_weight_name = \"d_weight_01.h5\"\n",
    "\n",
    "L_h, L_w, channels = LR_shape\n",
    "H_h = L_h * ratio\n",
    "H_w = L_w * ratio\n",
    "# HR_shape = np.array([H_h, H_w, c])\n",
    "HR_shape = (H_h, H_w, channels)\n",
    "\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def save_images(epoch, hr_img, lr_img, sr_img):\n",
    "    hr_img = denormalize(hr_img)\n",
    "    lr_img = denormalize(lr_img)\n",
    "    sr_img = denormalize(sr_img)\n",
    "    \n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_HRimage.png\", hr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_LRimage.png\", lr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_SRimage.png\", sr_img)\n",
    "\n",
    "    \n",
    "def calc_psnr(img1: np.ndarray, img2: np.ndarray):\n",
    "    def convert(img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    def extract_y(image: np.ndarray) -> np.ndarray:\n",
    "        if image.ndim == 2:\n",
    "            return image\n",
    "        image = image.astype(np.int32)\n",
    "        return ((image[:, :, 2] * 65.481 / 255.\n",
    "                  + image[:, :, 1] * 128.553 / 255.\n",
    "                  + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n",
    "\n",
    "\n",
    "    def psnr(img1, img2):\n",
    "        mse = np.mean((img1 - img2) ** 2)\n",
    "        if mse == 0:\n",
    "            return 100\n",
    "        PIXEL_MAX = 255.0\n",
    "        return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n",
    "\n",
    "    img1_conv=convert(img1)\n",
    "    img2_conv=convert(img2)\n",
    "\n",
    "    # BGR -> YCrCb\n",
    "    # 画像はcv2.imreadで読まれている前提 [0, 255]\n",
    "    y1 = extract_y(img1_conv)\n",
    "    y2 = extract_y(img2_conv)\n",
    "    # 周囲のcropping\n",
    "    # assert y1.shape == y2.shape\n",
    "    h, w = y1.shape\n",
    "    cr = ratio\n",
    "    cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "    cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "\n",
    "    # psnr\n",
    "    psnr_val = psnr(cropped_y1, cropped_y2)\n",
    "    return psnr_val\n",
    "\n",
    "\n",
    "def load_data(batch_size):\n",
    "\n",
    "    files = glob.glob(\"../../images/train/*.png\", recursive=True)\n",
    "    batch_images = random.sample(files, batch_size)\n",
    "\n",
    "    hr_imgs = []\n",
    "    lr_imgs = []\n",
    "    for img_path in batch_images:\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        hr_img = img.resize((H_w, H_h))  #(64, 64)\n",
    "        lr_img = img.resize((L_w, L_h))\n",
    "        hr_img = np.array(hr_img)\n",
    "        #img_hr = (img_hr - 127.5) / 127.5\n",
    "        lr_img = np.array(lr_img)\n",
    "        #img_lr = (img_lr - 127.5) / 127.5\n",
    "\n",
    "        hr_imgs.append(hr_img)\n",
    "        lr_imgs.append(lr_img)\n",
    "\n",
    "    hr_imgs = np.array(hr_imgs) / 127.5 - 1.\n",
    "    lr_imgs = np.array(lr_imgs) / 127.5 - 1.\n",
    "\n",
    "    return hr_imgs, lr_imgs\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pixel_shuffle(in_map, h, w, c):#((120, 160, 12), 120, 160, 3)\n",
    "    \n",
    "    x = Reshape((h, w, 2, 2, c))(in_map)\n",
    "    x = Permute((3, 1, 4, 2, 5))(x)\n",
    "    out_map = Reshape((2 * h, 2 * w, c))(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def upsampling(in_map, h, w, c):#((, 120, 160, 3), g:120, 160 , 64\n",
    "    \n",
    "    x = Conv2D(filters = 4 * c, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     padding = \"same\")(in_map)# x: 120, 160, 12\n",
    "    x = pixel_shuffle(x, h, w, c)# ( , 120, 160, 3)\n",
    "    out_map = PReLU()(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def residual_block(in_map):\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(in_map)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = PReLU()(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out_map = Add()([x, in_map])\n",
    "    return out_map\n",
    "\n",
    "\n",
    "def d_block(in_map, filters, kernel_size, strides, padding):\n",
    "    d = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)(in_map)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    middle = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(input_img)\n",
    "    middle = PReLU()(middle)\n",
    "    \n",
    "    g = residual_block(middle)\n",
    "    for _ in range(4):\n",
    "        g = residual_block(g)\n",
    "\n",
    "    g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = Add()([g, middle])\n",
    "\n",
    "    n = ratio\n",
    "    i = 1\n",
    "    while(n % 2 == 0):\n",
    "        g = upsampling(g, L_h * i, L_w * i, channels)#(g, 120, 160, 3), g:120, 160 , 64\n",
    "        i = i * 2\n",
    "        n = n // 2\n",
    "\n",
    "    output_img = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(g)\n",
    "\n",
    "    return Model(input_img, output_img)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = Input(shape = HR_shape)\n",
    "    \n",
    "    d = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(input_img)\n",
    "    d = d_block(d, filters = 64, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = Flatten()(d)\n",
    "    d = Dense(256)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    output = Dense(1, activation = \"sigmoid\")(d)\n",
    "\n",
    "    return Model(input_img, output)\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def build_vgg():\n",
    "    vgg = VGG19(include_top = False)\n",
    "    return Model(vgg.input, vgg.layers[9].output)\n",
    "    \n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def combined(generator, discriminator, vgg):\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    fake_img = generator(input_img)\n",
    "    \n",
    "    validity = discriminator(fake_img)\n",
    "    features = vgg(fake_img)\n",
    "    \n",
    "    return Model(input_img, [validity, features])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs_checkpoint = []\n",
    "psnr = []\n",
    "\n",
    "def train(epochs, batch_size, interval):\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        real_imgs, lr_imgs = load_data(batch_size)\n",
    "        fake_imgs = generator.predict(lr_imgs)\n",
    "        \n",
    "        #Dの訓練\n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        #Gの訓練\n",
    "        vgg_features = vgg.predict(real_imgs)\n",
    "        g_loss = srgan.train_on_batch(lr_imgs, [real, vgg_features])\n",
    "        \n",
    "        time = datetime.datetime.now() - start_time\n",
    "        print(\"%d time: %s\" % (epoch+1, time))\n",
    "        \n",
    "        if (epoch+1) % interval == 0:\n",
    "            print(\"epoch: %d\" % (epoch+1))\n",
    "            losses.append((d_loss, g_loss))\n",
    "            epochs_checkpoint.append(epoch+1)\n",
    "            save_images(epoch, real_imgs[0], lr_imgs[0], fake_imgs[0])\n",
    "#             psnr.append(calc_psnr(real_imgs[0], fake_imgs[0]))\n",
    "            \n",
    "    generator.save_weights(g_weight_name)\n",
    "    discriminator.save_weights(d_weight_name)\n",
    "    print(\"save seights\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 480, 640, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 240, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 320, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 240, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 240, 320, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 240, 320, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 120, 160, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 120, 160, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 120, 160, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 120, 160, 256)     295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 160, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 120, 160, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 80, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 80, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 80, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 60, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 40, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 614400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               157286656 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 161,979,713\n",
      "Trainable params: 161,976,001\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 160, 64)      15616     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 120, 160, 64)      1228800   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_1 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_3 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_4 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_5 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_6 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 120, 160, 12)      6924      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 120, 160, 2, 2, 3) 0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 2, 120, 2, 160, 3) 0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 240, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 240, 320, 3)       230400    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 240, 320, 12)      336       \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 240, 320, 2, 2, 3) 0         \n",
      "_________________________________________________________________\n",
      "permute_2 (Permute)          (None, 2, 240, 2, 320, 3) 0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 480, 640, 3)       921600    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 480, 640, 3)       732       \n",
      "=================================================================\n",
      "Total params: 2,813,432\n",
      "Trainable params: 2,812,024\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:146: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 120, 160, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 480, 640, 3)   2813432                                      \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 1)             161979713                                    \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  multiple              1735488                                      \n",
      "====================================================================================================\n",
      "Total params: 166,528,633\n",
      "Trainable params: 166,523,513\n",
      "Non-trainable params: 5,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------\n",
    "# メインプログラム\n",
    "#------------------------------------\n",
    "\n",
    "#Discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss = \"mse\",\n",
    "                      optimizer = optimizer,\n",
    "                      metrics = [\"accuracy\"])\n",
    "discriminator.summary()\n",
    "\n",
    "#Generator\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "vgg = build_vgg()\n",
    "vgg.trainable = False\n",
    "discriminator.trainable = False\n",
    "srgan = combined(generator, discriminator, vgg)\n",
    "srgan.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "srgan.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:521: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "1 time: 0:00:14.601319\n",
      "2 time: 0:00:15.082756\n",
      "3 time: 0:00:15.566779\n",
      "4 time: 0:00:16.035002\n",
      "5 time: 0:00:16.501269\n",
      "6 time: 0:00:16.972697\n",
      "7 time: 0:00:17.448129\n",
      "8 time: 0:00:17.921062\n",
      "9 time: 0:00:18.383063\n",
      "10 time: 0:00:18.855492\n",
      "epoch: 10\n",
      "11 time: 0:00:19.350446\n",
      "12 time: 0:00:19.823937\n",
      "13 time: 0:00:20.281947\n",
      "14 time: 0:00:20.756377\n",
      "15 time: 0:00:21.234812\n",
      "16 time: 0:00:21.715847\n",
      "17 time: 0:00:22.165108\n",
      "18 time: 0:00:22.650270\n",
      "19 time: 0:00:23.124700\n",
      "20 time: 0:00:23.601133\n",
      "epoch: 20\n",
      "21 time: 0:00:24.085237\n",
      "22 time: 0:00:24.569657\n",
      "23 time: 0:00:25.050094\n",
      "24 time: 0:00:25.525029\n",
      "25 time: 0:00:25.988008\n",
      "26 time: 0:00:26.459044\n",
      "27 time: 0:00:26.934475\n",
      "28 time: 0:00:27.419916\n",
      "29 time: 0:00:27.906653\n",
      "30 time: 0:00:28.377923\n",
      "epoch: 30\n",
      "31 time: 0:00:28.891894\n",
      "32 time: 0:00:29.372330\n",
      "33 time: 0:00:29.856770\n",
      "34 time: 0:00:30.321919\n",
      "35 time: 0:00:30.801355\n",
      "36 time: 0:00:31.287392\n",
      "37 time: 0:00:31.778838\n",
      "38 time: 0:00:32.240760\n",
      "39 time: 0:00:32.727708\n",
      "40 time: 0:00:33.196124\n",
      "epoch: 40\n",
      "41 time: 0:00:33.681456\n",
      "42 time: 0:00:34.149047\n",
      "43 time: 0:00:34.594079\n",
      "44 time: 0:00:35.044587\n",
      "45 time: 0:00:35.490691\n",
      "46 time: 0:00:35.950506\n",
      "47 time: 0:00:36.393971\n",
      "48 time: 0:00:36.842012\n",
      "49 time: 0:00:37.286359\n",
      "50 time: 0:00:37.729858\n",
      "epoch: 50\n",
      "51 time: 0:00:38.209335\n",
      "52 time: 0:00:38.669268\n",
      "53 time: 0:00:39.112511\n",
      "54 time: 0:00:39.573655\n",
      "55 time: 0:00:40.018713\n",
      "56 time: 0:00:40.485691\n",
      "57 time: 0:00:40.975261\n",
      "58 time: 0:00:41.436256\n",
      "59 time: 0:00:41.879817\n",
      "60 time: 0:00:42.342189\n",
      "epoch: 60\n",
      "61 time: 0:00:42.808828\n",
      "62 time: 0:00:43.269929\n",
      "63 time: 0:00:43.731377\n",
      "64 time: 0:00:44.188868\n",
      "65 time: 0:00:44.652479\n",
      "66 time: 0:00:45.127849\n",
      "67 time: 0:00:45.592833\n",
      "68 time: 0:00:46.036517\n",
      "69 time: 0:00:46.498369\n",
      "70 time: 0:00:46.957426\n",
      "epoch: 70\n",
      "71 time: 0:00:47.442085\n",
      "72 time: 0:00:47.915505\n",
      "73 time: 0:00:48.374756\n",
      "74 time: 0:00:48.835459\n",
      "75 time: 0:00:49.282309\n",
      "76 time: 0:00:49.729130\n",
      "77 time: 0:00:50.176486\n",
      "78 time: 0:00:50.636509\n",
      "79 time: 0:00:51.091317\n",
      "80 time: 0:00:51.550378\n",
      "epoch: 80\n",
      "81 time: 0:00:52.033503\n",
      "82 time: 0:00:52.477287\n",
      "83 time: 0:00:52.931792\n",
      "84 time: 0:00:53.425326\n",
      "85 time: 0:00:53.884626\n",
      "86 time: 0:00:54.326826\n",
      "87 time: 0:00:54.794581\n",
      "88 time: 0:00:55.238910\n",
      "89 time: 0:00:55.697322\n",
      "90 time: 0:00:56.142587\n",
      "epoch: 90\n",
      "91 time: 0:00:56.624155\n",
      "92 time: 0:00:57.079021\n",
      "93 time: 0:00:57.517257\n",
      "94 time: 0:00:57.974840\n",
      "95 time: 0:00:58.416751\n",
      "96 time: 0:00:58.878812\n",
      "97 time: 0:00:59.336375\n",
      "98 time: 0:00:59.781350\n",
      "99 time: 0:01:00.229218\n",
      "100 time: 0:01:00.672338\n",
      "epoch: 100\n",
      "101 time: 0:01:01.155096\n",
      "102 time: 0:01:01.600365\n",
      "103 time: 0:01:02.042326\n",
      "104 time: 0:01:02.499784\n",
      "105 time: 0:01:02.944995\n",
      "106 time: 0:01:03.386890\n",
      "107 time: 0:01:03.844304\n",
      "108 time: 0:01:04.289447\n",
      "109 time: 0:01:04.731363\n",
      "110 time: 0:01:05.173159\n",
      "epoch: 110\n",
      "111 time: 0:01:05.649736\n",
      "112 time: 0:01:06.107006\n",
      "113 time: 0:01:06.564610\n",
      "114 time: 0:01:07.010037\n",
      "115 time: 0:01:07.452480\n",
      "116 time: 0:01:07.894231\n",
      "117 time: 0:01:08.339229\n",
      "118 time: 0:01:08.796617\n",
      "119 time: 0:01:09.238553\n",
      "120 time: 0:01:09.680644\n",
      "epoch: 120\n",
      "121 time: 0:01:10.152334\n",
      "122 time: 0:01:10.609741\n",
      "123 time: 0:01:11.054118\n",
      "124 time: 0:01:11.508943\n",
      "125 time: 0:01:11.950801\n",
      "126 time: 0:01:12.397158\n",
      "127 time: 0:01:12.853199\n",
      "128 time: 0:01:13.294840\n",
      "129 time: 0:01:13.744652\n",
      "130 time: 0:01:14.199934\n",
      "epoch: 130\n",
      "131 time: 0:01:14.668469\n",
      "132 time: 0:01:15.131354\n",
      "133 time: 0:01:15.576803\n",
      "134 time: 0:01:16.020820\n",
      "135 time: 0:01:16.464142\n",
      "136 time: 0:01:16.921735\n",
      "137 time: 0:01:17.363719\n",
      "138 time: 0:01:17.808803\n",
      "139 time: 0:01:18.250710\n",
      "140 time: 0:01:18.708089\n",
      "epoch: 140\n",
      "141 time: 0:01:19.184385\n",
      "142 time: 0:01:19.626337\n",
      "143 time: 0:01:20.068346\n",
      "144 time: 0:01:20.529839\n",
      "145 time: 0:01:20.974349\n",
      "146 time: 0:01:21.417166\n",
      "147 time: 0:01:21.877900\n",
      "148 time: 0:01:22.320004\n",
      "149 time: 0:01:22.761912\n",
      "150 time: 0:01:23.205821\n",
      "epoch: 150\n",
      "151 time: 0:01:23.702694\n",
      "152 time: 0:01:24.157613\n",
      "153 time: 0:01:24.602890\n",
      "154 time: 0:01:25.062707\n",
      "155 time: 0:01:25.504711\n",
      "156 time: 0:01:25.948758\n",
      "157 time: 0:01:26.407521\n",
      "158 time: 0:01:26.876793\n",
      "159 time: 0:01:27.348946\n",
      "160 time: 0:01:27.806338\n",
      "epoch: 160\n",
      "161 time: 0:01:28.293573\n",
      "162 time: 0:01:28.736719\n",
      "163 time: 0:01:29.194319\n",
      "164 time: 0:01:29.651859\n",
      "165 time: 0:01:30.106472\n",
      "166 time: 0:01:30.566885\n",
      "167 time: 0:01:31.011274\n",
      "168 time: 0:01:31.455817\n",
      "169 time: 0:01:31.917597\n",
      "170 time: 0:01:32.359560\n",
      "epoch: 170\n",
      "171 time: 0:01:32.835723\n",
      "172 time: 0:01:33.277566\n",
      "173 time: 0:01:33.735095\n",
      "174 time: 0:01:34.193789\n",
      "175 time: 0:01:34.635564\n",
      "176 time: 0:01:35.077336\n",
      "177 time: 0:01:35.538001\n",
      "178 time: 0:01:35.982235\n",
      "179 time: 0:01:36.425366\n",
      "180 time: 0:01:36.870512\n",
      "epoch: 180\n",
      "181 time: 0:01:37.343972\n",
      "182 time: 0:01:37.794448\n",
      "183 time: 0:01:38.278337\n",
      "184 time: 0:01:38.735766\n",
      "185 time: 0:01:39.193202\n",
      "186 time: 0:01:39.636443\n",
      "187 time: 0:01:40.096663\n",
      "188 time: 0:01:40.540871\n",
      "189 time: 0:01:41.000461\n",
      "190 time: 0:01:41.445059\n",
      "epoch: 190\n",
      "191 time: 0:01:41.928738\n",
      "192 time: 0:01:42.373728\n",
      "193 time: 0:01:42.831287\n",
      "194 time: 0:01:43.289540\n",
      "195 time: 0:01:43.734934\n",
      "196 time: 0:01:44.176757\n",
      "197 time: 0:01:44.634312\n",
      "198 time: 0:01:45.079252\n",
      "199 time: 0:01:45.521067\n",
      "200 time: 0:01:45.974505\n",
      "epoch: 200\n",
      "201 time: 0:01:46.451056\n",
      "202 time: 0:01:46.892751\n",
      "203 time: 0:01:47.350520\n",
      "204 time: 0:01:47.808809\n",
      "205 time: 0:01:48.250721\n",
      "206 time: 0:01:48.708201\n",
      "207 time: 0:01:49.153509\n",
      "208 time: 0:01:49.595600\n",
      "209 time: 0:01:50.037547\n",
      "210 time: 0:01:50.483918\n",
      "epoch: 210\n",
      "211 time: 0:01:50.960433\n",
      "212 time: 0:01:51.403492\n",
      "213 time: 0:01:51.865399\n",
      "214 time: 0:01:52.307418\n",
      "215 time: 0:01:52.764904\n",
      "216 time: 0:01:53.208982\n",
      "217 time: 0:01:53.667551\n",
      "218 time: 0:01:54.109328\n",
      "219 time: 0:01:54.551274\n",
      "220 time: 0:01:55.008551\n",
      "epoch: 220\n",
      "221 time: 0:01:55.481534\n",
      "222 time: 0:01:55.925670\n",
      "223 time: 0:01:56.389312\n",
      "224 time: 0:01:56.831612\n",
      "225 time: 0:01:57.291263\n",
      "226 time: 0:01:57.735055\n",
      "227 time: 0:01:58.192348\n",
      "228 time: 0:01:58.636476\n",
      "229 time: 0:01:59.079523\n",
      "230 time: 0:01:59.521521\n",
      "epoch: 230\n",
      "231 time: 0:01:59.996078\n",
      "232 time: 0:02:00.454774\n",
      "233 time: 0:02:00.899248\n",
      "234 time: 0:02:01.362681\n",
      "235 time: 0:02:01.805844\n",
      "236 time: 0:02:02.261283\n",
      "237 time: 0:02:02.713604\n",
      "238 time: 0:02:03.172312\n",
      "239 time: 0:02:03.633984\n",
      "240 time: 0:02:04.079575\n",
      "epoch: 240\n",
      "241 time: 0:02:04.553685\n",
      "242 time: 0:02:05.021473\n",
      "243 time: 0:02:05.465705\n",
      "244 time: 0:02:05.926786\n",
      "245 time: 0:02:06.369801\n",
      "246 time: 0:02:06.823133\n",
      "247 time: 0:02:07.299676\n",
      "248 time: 0:02:07.742750\n",
      "249 time: 0:02:08.222435\n",
      "250 time: 0:02:08.702871\n",
      "epoch: 250\n",
      "251 time: 0:02:09.214335\n",
      "252 time: 0:02:09.690069\n",
      "253 time: 0:02:10.153208\n",
      "254 time: 0:02:10.649723\n",
      "255 time: 0:02:11.133045\n",
      "256 time: 0:02:11.626174\n",
      "257 time: 0:02:12.104812\n",
      "258 time: 0:02:12.579560\n",
      "259 time: 0:02:13.049282\n",
      "260 time: 0:02:13.492612\n",
      "epoch: 260\n",
      "261 time: 0:02:13.979751\n",
      "262 time: 0:02:14.423764\n",
      "263 time: 0:02:14.878214\n",
      "264 time: 0:02:15.331902\n",
      "265 time: 0:02:15.783525\n",
      "266 time: 0:02:16.230155\n",
      "267 time: 0:02:16.684277\n",
      "268 time: 0:02:17.147369\n",
      "269 time: 0:02:17.588844\n",
      "270 time: 0:02:18.061765\n",
      "epoch: 270\n",
      "271 time: 0:02:18.543064\n",
      "272 time: 0:02:19.017150\n",
      "273 time: 0:02:19.470015\n",
      "274 time: 0:02:19.927383\n",
      "275 time: 0:02:20.386114\n",
      "276 time: 0:02:20.844642\n",
      "277 time: 0:02:21.298143\n",
      "278 time: 0:02:21.753556\n",
      "279 time: 0:02:22.205967\n",
      "280 time: 0:02:22.655375\n",
      "epoch: 280\n",
      "281 time: 0:02:23.134809\n",
      "282 time: 0:02:23.581214\n",
      "283 time: 0:02:24.034129\n",
      "284 time: 0:02:24.487045\n",
      "285 time: 0:02:24.933450\n",
      "286 time: 0:02:25.380856\n",
      "287 time: 0:02:25.829767\n",
      "288 time: 0:02:26.278175\n",
      "289 time: 0:02:26.736095\n",
      "290 time: 0:02:27.182499\n",
      "epoch: 290\n",
      "291 time: 0:02:27.662935\n",
      "292 time: 0:02:28.113344\n",
      "293 time: 0:02:28.562752\n",
      "294 time: 0:02:29.009157\n",
      "295 time: 0:02:29.456563\n",
      "296 time: 0:02:29.913978\n",
      "297 time: 0:02:30.367225\n",
      "298 time: 0:02:30.809159\n",
      "299 time: 0:02:31.265350\n",
      "300 time: 0:02:31.717760\n",
      "epoch: 300\n",
      "301 time: 0:02:32.213210\n",
      "302 time: 0:02:32.707163\n",
      "303 time: 0:02:33.199610\n",
      "304 time: 0:02:33.675233\n",
      "305 time: 0:02:34.120218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 time: 0:02:34.577981\n",
      "307 time: 0:02:35.020152\n",
      "308 time: 0:02:35.479992\n",
      "309 time: 0:02:35.938350\n",
      "310 time: 0:02:36.380222\n",
      "epoch: 310\n",
      "311 time: 0:02:36.856880\n",
      "312 time: 0:02:37.327090\n",
      "313 time: 0:02:37.790511\n",
      "314 time: 0:02:38.241920\n",
      "315 time: 0:02:38.691328\n",
      "316 time: 0:02:39.141242\n",
      "317 time: 0:02:39.591650\n",
      "318 time: 0:02:40.040563\n",
      "319 time: 0:02:40.494975\n",
      "320 time: 0:02:40.946384\n",
      "epoch: 320\n",
      "321 time: 0:02:41.425819\n",
      "322 time: 0:02:41.882739\n",
      "323 time: 0:02:42.344663\n",
      "324 time: 0:02:42.794070\n",
      "325 time: 0:02:43.254488\n",
      "326 time: 0:02:43.743932\n",
      "327 time: 0:02:44.227372\n",
      "328 time: 0:02:44.704804\n",
      "329 time: 0:02:45.153715\n",
      "330 time: 0:02:45.602627\n",
      "epoch: 330\n",
      "331 time: 0:02:46.078563\n",
      "332 time: 0:02:46.524976\n",
      "333 time: 0:02:46.987396\n",
      "334 time: 0:02:47.448815\n",
      "335 time: 0:02:47.902226\n",
      "336 time: 0:02:48.351138\n",
      "337 time: 0:02:48.807057\n",
      "338 time: 0:02:49.264472\n",
      "339 time: 0:02:49.735902\n",
      "340 time: 0:02:50.201326\n",
      "epoch: 340\n",
      "341 time: 0:02:50.684897\n",
      "342 time: 0:02:51.133809\n",
      "343 time: 0:02:51.588726\n",
      "344 time: 0:02:52.039134\n",
      "345 time: 0:02:52.489544\n",
      "346 time: 0:02:52.936950\n",
      "347 time: 0:02:53.385859\n",
      "348 time: 0:02:53.833899\n",
      "349 time: 0:02:54.291167\n",
      "350 time: 0:02:54.736297\n",
      "epoch: 350\n",
      "351 time: 0:02:55.229960\n",
      "352 time: 0:02:55.671855\n",
      "353 time: 0:02:56.118665\n",
      "354 time: 0:02:56.561590\n",
      "355 time: 0:02:57.019036\n",
      "356 time: 0:02:57.464234\n",
      "357 time: 0:02:57.905875\n",
      "358 time: 0:02:58.363302\n",
      "359 time: 0:02:58.808191\n",
      "360 time: 0:02:59.250055\n",
      "epoch: 360\n",
      "361 time: 0:02:59.723493\n",
      "362 time: 0:03:00.184114\n",
      "363 time: 0:03:00.626863\n",
      "364 time: 0:03:01.070976\n",
      "365 time: 0:03:01.513689\n",
      "366 time: 0:03:01.971082\n",
      "367 time: 0:03:02.413043\n",
      "368 time: 0:03:02.858027\n",
      "369 time: 0:03:03.299737\n",
      "370 time: 0:03:03.757291\n",
      "epoch: 370\n",
      "371 time: 0:03:04.234019\n",
      "372 time: 0:03:04.691415\n",
      "373 time: 0:03:05.133261\n",
      "374 time: 0:03:05.593813\n",
      "375 time: 0:03:06.038271\n",
      "376 time: 0:03:06.481229\n",
      "377 time: 0:03:06.926291\n",
      "378 time: 0:03:07.408977\n",
      "379 time: 0:03:07.900930\n",
      "380 time: 0:03:08.388373\n",
      "epoch: 380\n",
      "381 time: 0:03:08.910846\n",
      "382 time: 0:03:09.399796\n"
     ]
    }
   ],
   "source": [
    "train(epochs = 1000, batch_size = 1, interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(len(epochs_checkpoint)):\n",
    "    print(\"epoch: %d  d_loss: %.3f  g_loss: %.3f  psnr: %.3f\"\n",
    "         .format(epochs_checkpoint[epoch],\n",
    "                losses[epoch, 0],\n",
    "                losses[epoch, 1],\n",
    "                psnr[epoch]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_2/Sigmoid:0\", shape=(?, 30, 40, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "D = Discriminator(480, 640, 3)\n",
    "img = Image.open(\"../../images/train/image_1.png\")\n",
    "img = np.array(img)\n",
    "valid = D.discriminate(img)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
