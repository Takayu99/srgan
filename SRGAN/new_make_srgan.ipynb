{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Dense, Add, Reshape, Permute, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG19\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ratio = 4\n",
    "LR_shape = (120, 160, 3)\n",
    "g_weight_name = \"g_weight_01.h5\"\n",
    "d_weight_name = \"d_weight_01.h5\"\n",
    "\n",
    "L_h, L_w, channels = LR_shape\n",
    "H_h = L_h * ratio\n",
    "H_w = L_w * ratio\n",
    "# HR_shape = np.array([H_h, H_w, c])\n",
    "HR_shape = (H_h, H_w, channels)\n",
    "\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def save_images(epoch, hr_img, lr_img, sr_img):\n",
    "    hr_img = denormalize(hr_img)\n",
    "    lr_img = denormalize(lr_img)\n",
    "    sr_img = denormalize(sr_img)\n",
    "    \n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_HRimage.png\", hr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_LRimage.png\", lr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_SRimage.png\", sr_img)\n",
    "\n",
    "    \n",
    "def calc_psnr(img1: np.ndarray, img2: np.ndarray):\n",
    "    def convert(img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    def extract_y(image: np.ndarray) -> np.ndarray:\n",
    "        if image.ndim == 2:\n",
    "            return image\n",
    "        image = image.astype(np.int32)\n",
    "        return ((image[:, :, 2] * 65.481 / 255.\n",
    "                  + image[:, :, 1] * 128.553 / 255.\n",
    "                  + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n",
    "\n",
    "\n",
    "    def psnr(img1, img2):\n",
    "        mse = np.mean((img1 - img2) ** 2)\n",
    "        if mse == 0:\n",
    "            return 100\n",
    "        PIXEL_MAX = 255.0\n",
    "        return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n",
    "\n",
    "    img1_conv=convert(img1)\n",
    "    img2_conv=convert(img2)\n",
    "\n",
    "    # BGR -> YCrCb\n",
    "    # 画像はcv2.imreadで読まれている前提 [0, 255]\n",
    "    y1 = extract_y(img1_conv)\n",
    "    y2 = extract_y(img2_conv)\n",
    "    # 周囲のcropping\n",
    "    # assert y1.shape == y2.shape\n",
    "    h, w = y1.shape\n",
    "    cr = ratio\n",
    "    cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "    cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "\n",
    "    # psnr\n",
    "    psnr_val = psnr(cropped_y1, cropped_y2)\n",
    "    return psnr_val\n",
    "\n",
    "\n",
    "def load_data(batch_size):\n",
    "\n",
    "    files = glob.glob(\"../../images/train/*.png\", recursive=True)\n",
    "    batch_images = random.sample(files, batch_size)\n",
    "\n",
    "    hr_imgs = []\n",
    "    lr_imgs = []\n",
    "    for img_path in batch_images:\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        hr_img = img.resize((H_w, H_h))  #(64, 64)\n",
    "        lr_img = img.resize((L_w, L_h))\n",
    "        hr_img = np.array(hr_img)\n",
    "        #img_hr = (img_hr - 127.5) / 127.5\n",
    "        lr_img = np.array(lr_img)\n",
    "        #img_lr = (img_lr - 127.5) / 127.5\n",
    "\n",
    "        hr_imgs.append(hr_img)\n",
    "        lr_imgs.append(lr_img)\n",
    "\n",
    "    hr_imgs = np.array(hr_imgs) / 127.5 - 1.\n",
    "    lr_imgs = np.array(lr_imgs) / 127.5 - 1.\n",
    "\n",
    "    return hr_imgs, lr_imgs\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pixel_shuffle(in_map, h, w, c):#((120, 160, 12), 120, 160, 3)\n",
    "    \n",
    "    x = Reshape((h, w, 2, 2, c))(in_map)\n",
    "    x = Permute((3, 1, 4, 2, 5))(x)\n",
    "    out_map = Reshape((2 * h, 2 * w, c))(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def upsampling(in_map, h, w, c):#((, 120, 160, 3), g:120, 160 , 64\n",
    "    \n",
    "    x = Conv2D(filters = 4 * c, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     padding = \"same\")(in_map)# x: 120, 160, 12\n",
    "    x = pixel_shuffle(x, h, w, c)# ( , 120, 160, 3)\n",
    "    out_map = PReLU()(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def residual_block(in_map):\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(in_map)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = PReLU()(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out_map = Add()([x, in_map])\n",
    "    return out_map\n",
    "\n",
    "\n",
    "def d_block(in_map, filters, kernel_size, strides, padding):\n",
    "    d = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)(in_map)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    middle = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(input_img)\n",
    "    middle = PReLU()(middle)\n",
    "    \n",
    "    g = residual_block(middle)\n",
    "    for _ in range(4):\n",
    "        g = residual_block(g)\n",
    "\n",
    "    g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = Add()([g, middle])\n",
    "\n",
    "    n = ratio\n",
    "    i = 1\n",
    "    while(n % 2 == 0):\n",
    "        g = upsampling(g, L_h * i, L_w * i, channels)#(g, 120, 160, 3), g:120, 160 , 64\n",
    "        i = i * 2\n",
    "        n = n // 2\n",
    "\n",
    "    output_img = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(g)\n",
    "\n",
    "    return Model(input_img, output_img)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = Input(shape = HR_shape)\n",
    "    \n",
    "    d = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(input_img)\n",
    "    d = d_block(d, filters = 64, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = Flatten()(d)\n",
    "    d = Dense(256)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    output = Dense(1, activation = \"sigmoid\")(d)\n",
    "\n",
    "    return Model(input_img, output)\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def build_vgg():\n",
    "    vgg = VGG19(include_top = False)\n",
    "    return Model(vgg.input, vgg.layers[9].output)\n",
    "    \n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def combined(generator, discriminator, vgg):\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    fake_img = generator(input_img)\n",
    "    \n",
    "    validity = discriminator(fake_img)\n",
    "    features = vgg(fake_img)\n",
    "    \n",
    "    return Model(input_img, [validity, features])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs_checkpoint = []\n",
    "psnr = []\n",
    "\n",
    "def train(epochs, batch_size, interval):\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    real = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        real_imgs, lr_imgs = load_data(batch_size)\n",
    "        fake_imgs = generator.predict(lr_imgs)\n",
    "        \n",
    "        #Dの訓練\n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        #Gの訓練\n",
    "        vgg_features = vgg.predict(real_imgs)\n",
    "        g_loss = srgan.train_on_batch(lr_imgs, [real, vgg_features])\n",
    "        \n",
    "        time = datetime.datetime.now() - start_time\n",
    "        print(\"%d time: %s\" % (epoch+1, time))\n",
    "        \n",
    "        if (epoch+1) % interval == 0:\n",
    "            print(\"epoch: %d\" % (epoch+1))\n",
    "            losses.append((d_loss, g_loss))\n",
    "            epochs_checkpoint.append(epoch+1)\n",
    "            save_images(epoch, real_imgs[0], lr_imgs[0], fake_imgs[0])\n",
    "#             psnr.append(calc_psnr(real_imgs[0], fake_imgs[0]))\n",
    "            \n",
    "    generator.save_weights(g_weight_name)\n",
    "    discriminator.save_weights(d_weight_name)\n",
    "    print(\"save seights\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 480, 640, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 240, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 320, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 240, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 240, 320, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 240, 320, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 120, 160, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 120, 160, 128)     512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 120, 160, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 120, 160, 256)     295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 160, 256)     1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 120, 160, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 80, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 80, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 80, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 60, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 40, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 614400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               157286656 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 161,979,713\n",
      "Trainable params: 161,976,001\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 160, 64)      15616     \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 120, 160, 64)      1228800   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_1 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_3 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_4 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_5 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_6 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 120, 160, 12)      6924      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 120, 160, 2, 2, 3) 0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 2, 120, 2, 160, 3) 0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 240, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 240, 320, 3)       230400    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 240, 320, 12)      336       \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 240, 320, 2, 2, 3) 0         \n",
      "_________________________________________________________________\n",
      "permute_2 (Permute)          (None, 2, 240, 2, 320, 3) 0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 480, 640, 3)       921600    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 480, 640, 3)       732       \n",
      "=================================================================\n",
      "Total params: 2,813,432\n",
      "Trainable params: 2,812,024\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:146: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 120, 160, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 480, 640, 3)   2813432                                      \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 1)             161979713                                    \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  multiple              1735488                                      \n",
      "====================================================================================================\n",
      "Total params: 166,528,633\n",
      "Trainable params: 166,523,513\n",
      "Non-trainable params: 5,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------\n",
    "# メインプログラム\n",
    "#------------------------------------\n",
    "\n",
    "#Discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss = \"mse\",\n",
    "                      optimizer = optimizer,\n",
    "                      metrics = [\"accuracy\"])\n",
    "discriminator.summary()\n",
    "\n",
    "#Generator\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "vgg = build_vgg()\n",
    "vgg.trainable = False\n",
    "discriminator.trainable = False\n",
    "srgan = combined(generator, discriminator, vgg)\n",
    "srgan.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "srgan.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:521: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "1 time: 0:00:14.601319\n",
      "2 time: 0:00:15.082756\n",
      "3 time: 0:00:15.566779\n",
      "4 time: 0:00:16.035002\n",
      "5 time: 0:00:16.501269\n",
      "6 time: 0:00:16.972697\n",
      "7 time: 0:00:17.448129\n",
      "8 time: 0:00:17.921062\n",
      "9 time: 0:00:18.383063\n",
      "10 time: 0:00:18.855492\n",
      "epoch: 10\n",
      "11 time: 0:00:19.350446\n",
      "12 time: 0:00:19.823937\n",
      "13 time: 0:00:20.281947\n",
      "14 time: 0:00:20.756377\n",
      "15 time: 0:00:21.234812\n",
      "16 time: 0:00:21.715847\n",
      "17 time: 0:00:22.165108\n",
      "18 time: 0:00:22.650270\n",
      "19 time: 0:00:23.124700\n",
      "20 time: 0:00:23.601133\n",
      "epoch: 20\n",
      "21 time: 0:00:24.085237\n",
      "22 time: 0:00:24.569657\n",
      "23 time: 0:00:25.050094\n",
      "24 time: 0:00:25.525029\n",
      "25 time: 0:00:25.988008\n",
      "26 time: 0:00:26.459044\n",
      "27 time: 0:00:26.934475\n",
      "28 time: 0:00:27.419916\n",
      "29 time: 0:00:27.906653\n",
      "30 time: 0:00:28.377923\n",
      "epoch: 30\n",
      "31 time: 0:00:28.891894\n",
      "32 time: 0:00:29.372330\n",
      "33 time: 0:00:29.856770\n",
      "34 time: 0:00:30.321919\n",
      "35 time: 0:00:30.801355\n",
      "36 time: 0:00:31.287392\n",
      "37 time: 0:00:31.778838\n",
      "38 time: 0:00:32.240760\n",
      "39 time: 0:00:32.727708\n",
      "40 time: 0:00:33.196124\n",
      "epoch: 40\n",
      "41 time: 0:00:33.681456\n",
      "42 time: 0:00:34.149047\n",
      "43 time: 0:00:34.594079\n",
      "44 time: 0:00:35.044587\n",
      "45 time: 0:00:35.490691\n",
      "46 time: 0:00:35.950506\n",
      "47 time: 0:00:36.393971\n",
      "48 time: 0:00:36.842012\n",
      "49 time: 0:00:37.286359\n",
      "50 time: 0:00:37.729858\n",
      "epoch: 50\n",
      "51 time: 0:00:38.209335\n",
      "52 time: 0:00:38.669268\n",
      "53 time: 0:00:39.112511\n",
      "54 time: 0:00:39.573655\n",
      "55 time: 0:00:40.018713\n",
      "56 time: 0:00:40.485691\n",
      "57 time: 0:00:40.975261\n",
      "58 time: 0:00:41.436256\n",
      "59 time: 0:00:41.879817\n",
      "60 time: 0:00:42.342189\n",
      "epoch: 60\n",
      "61 time: 0:00:42.808828\n",
      "62 time: 0:00:43.269929\n",
      "63 time: 0:00:43.731377\n",
      "64 time: 0:00:44.188868\n",
      "65 time: 0:00:44.652479\n",
      "66 time: 0:00:45.127849\n",
      "67 time: 0:00:45.592833\n",
      "68 time: 0:00:46.036517\n",
      "69 time: 0:00:46.498369\n",
      "70 time: 0:00:46.957426\n",
      "epoch: 70\n",
      "71 time: 0:00:47.442085\n",
      "72 time: 0:00:47.915505\n",
      "73 time: 0:00:48.374756\n",
      "74 time: 0:00:48.835459\n",
      "75 time: 0:00:49.282309\n",
      "76 time: 0:00:49.729130\n",
      "77 time: 0:00:50.176486\n",
      "78 time: 0:00:50.636509\n",
      "79 time: 0:00:51.091317\n",
      "80 time: 0:00:51.550378\n",
      "epoch: 80\n",
      "81 time: 0:00:52.033503\n",
      "82 time: 0:00:52.477287\n",
      "83 time: 0:00:52.931792\n",
      "84 time: 0:00:53.425326\n",
      "85 time: 0:00:53.884626\n",
      "86 time: 0:00:54.326826\n",
      "87 time: 0:00:54.794581\n",
      "88 time: 0:00:55.238910\n",
      "89 time: 0:00:55.697322\n",
      "90 time: 0:00:56.142587\n",
      "epoch: 90\n",
      "91 time: 0:00:56.624155\n",
      "92 time: 0:00:57.079021\n",
      "93 time: 0:00:57.517257\n",
      "94 time: 0:00:57.974840\n",
      "95 time: 0:00:58.416751\n",
      "96 time: 0:00:58.878812\n",
      "97 time: 0:00:59.336375\n",
      "98 time: 0:00:59.781350\n",
      "99 time: 0:01:00.229218\n",
      "100 time: 0:01:00.672338\n",
      "epoch: 100\n",
      "101 time: 0:01:01.155096\n",
      "102 time: 0:01:01.600365\n",
      "103 time: 0:01:02.042326\n",
      "104 time: 0:01:02.499784\n",
      "105 time: 0:01:02.944995\n",
      "106 time: 0:01:03.386890\n",
      "107 time: 0:01:03.844304\n",
      "108 time: 0:01:04.289447\n",
      "109 time: 0:01:04.731363\n",
      "110 time: 0:01:05.173159\n",
      "epoch: 110\n",
      "111 time: 0:01:05.649736\n",
      "112 time: 0:01:06.107006\n",
      "113 time: 0:01:06.564610\n",
      "114 time: 0:01:07.010037\n",
      "115 time: 0:01:07.452480\n",
      "116 time: 0:01:07.894231\n",
      "117 time: 0:01:08.339229\n",
      "118 time: 0:01:08.796617\n",
      "119 time: 0:01:09.238553\n"
     ]
    }
   ],
   "source": [
    "train(epochs = 1000, batch_size = 1, interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(len(epochs_checkpoint)):\n",
    "    print(\"epoch: %d  d_loss: %.3f  g_loss: %.3f  psnr: %.3f\"\n",
    "         .format(epochs_checkpoint[epoch],\n",
    "                losses[epoch, 0],\n",
    "                losses[epoch, 1],\n",
    "                psnr[epoch]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_2/Sigmoid:0\", shape=(?, 30, 40, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "D = Discriminator(480, 640, 3)\n",
    "img = Image.open(\"../../images/train/image_1.png\")\n",
    "img = np.array(img)\n",
    "valid = D.discriminate(img)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
