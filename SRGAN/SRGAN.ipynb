{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import csv\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "[120 160]\n"
     ]
    }
   ],
   "source": [
    "ratio = 4\n",
    "channels = 3\n",
    "HR_size = np.array([480,640])#\n",
    "LR_size = HR_size // ratio\n",
    "H_h = HR_size[0]\n",
    "H_w = HR_size[1]\n",
    "L_h = LR_size[0]\n",
    "L_w = LR_size[1]\n",
    "print(HR_size[0])\n",
    "print(LR_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "#         self.ratio = ratio\n",
    "#         self.HR_size = HR_size\n",
    "#         self.LR_size = HR_size / ratio\n",
    "#         self.H_h = HR_size[0]\n",
    "#         self.H_w = HR_size[1]\n",
    "#         self.L_h = LR_size[0]\n",
    "#         self.L_h = LR_size[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def load_data(self, batch_size = 1):\n",
    "        files = glob.glob(\"../../images/train/*.png\", recursive=True)\n",
    "        batch_images = random.sample(files, batch_size)\n",
    "    \n",
    "        HR_images = []\n",
    "        LR_images = []\n",
    "    \n",
    "        for img_path in batch_images:\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            HR_image = img.resize((H_w, H_h))  #(64, 64)\n",
    "            LR_image = img.resize((L_w, L_h))\n",
    "            HR_image = np.array(HR_image)\n",
    "            #img_hr = (img_hr - 127.5) / 127.5\n",
    "            LR_image = np.array(LR_image)\n",
    "            #img_lr = (img_lr - 127.5) / 127.5\n",
    "\n",
    "#             if not is_testing and np.random.random() < 0.5:\n",
    "#                 img_hr = np.fliplr(img_hr)\n",
    "#                 img_lr = np.fliplr(img_lr)\n",
    "\n",
    "            HR_images.append(HR_image)\n",
    "            LR_images.append(LR_image)\n",
    "        \n",
    "        HR_images = np.array(HR_images) / 127.5 - 1\n",
    "        LR_images = np.array(LR_images) / 127.5 - 1\n",
    "        \n",
    "        return HR_images, LR_images\n",
    "\n",
    "#------------------------------------------------------------------#\n",
    "  \n",
    "#------------------------------------------------------------------#\n",
    "\n",
    "class predDataLoader():          \n",
    "    def load_data(self, batch_size, counter):\n",
    "        random.seed(counter)\n",
    "        np.random.seed(counter)\n",
    "\n",
    "        files = glob.glob(\"../../images/test/*.png\", recursive=True)\n",
    "        batch_images = random.sample(files, batch_size)\n",
    "\n",
    "        imgs_or = []\n",
    "        for img_path in batch_images:\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            img_or = np.array(img)\n",
    "            imgs_or.append(img_or)\n",
    "\n",
    "        imgs_or = np.array(imgs_or) / 127.5 - 1.\n",
    "\n",
    "        return imgs_or\n",
    "    \n",
    "    \n",
    "#------------------------------------------------------------------#\n",
    "  \n",
    "#------------------------------------------------------------------#\n",
    "\n",
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Input shape\n",
    "#         self.channels = 3\n",
    "#         self.lr_height = 288                 # Low resolution height\n",
    "#         self.lr_width = 384                  # Low resolution width\n",
    "#         self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n",
    "#         resLevel = 2 #\n",
    "#         self.hr_height = self.lr_height*resLevel  # High resolution height\n",
    "#         self.hr_width = self.lr_width*resLevel     # High resolution width\n",
    "#         self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n",
    "\n",
    "        #残差ブロックの数\n",
    "        # Number of residual blocks in the generator\n",
    "        self.n_residual_blocks = 16 #\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        #img_hrの特徴量をVGG19で算出する\n",
    "        # We use a pre-trained VGG19 model to extract image features from the high resolution\n",
    "        # and the generated high resolution images and minimize the mse between them\n",
    "        self.VGG = self.build_vgg()\n",
    "        self.VGG.trainable = False\n",
    "        self.VGG.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "        #データはここで読み込まれる\n",
    "        # Configure data loader\n",
    "        #self.dataset_name = 'img_align_celeba'\n",
    "        self.data_loader = DataLoader()\n",
    "        self.pred_data_loader = predDataLoader()\n",
    "\n",
    "        #Dのサイズ\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patchH = int(H_h / 2**4) #\n",
    "        patchW = int(H_w / 2**4) #\n",
    "        self.disc_patch = (patchH, patchW, 1) \n",
    "\n",
    "        #DとGのチャンネル設定\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 60 #gf\n",
    "        self.df = 60 #df\n",
    "        #Dビルドとコンパイル\n",
    "        # Build and compile the discriminator\n",
    "        self.Discriminator = self.build_discriminator()\n",
    "        self.Discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #Gのビルド\n",
    "        # Build the generator\n",
    "        self.Generator = self.build_generator()\n",
    "\n",
    "        # High res. and low res. images\n",
    "        HR_image = Input(shape = (H_h, H_w, channels))\n",
    "        LR_image = Input(shape = (L_h, L_w, channels))\n",
    "\n",
    "        #Gで生成されたhrのimg\n",
    "        # Generate high res. version from low res.\n",
    "        SR_image = self.Generator(LR_image)\n",
    "\n",
    "        #hrのimgの特徴量の算出\n",
    "        # Extract image features of the generated img\n",
    "        SR_features = self.VGG(SR_image)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.Discriminator.trainable = False\n",
    "\n",
    "        #学習モデルコンパイル\n",
    "        # Discriminator determines validity of generated high res. images\n",
    "        validity = self.Discriminator(SR_image)\n",
    "\n",
    "        self.combined = Model([LR_image, HR_image], [validity, SR_features])\n",
    "        self.combined.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "        \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    def build_vgg(self):\n",
    "        \"\"\"\n",
    "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
    "        third block of the model\n",
    "        \"\"\"\n",
    "        VGG = VGG19(weights=\"imagenet\")\n",
    "        # Set outputs to outputs of last conv. layer in block 3\n",
    "        # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
    "        VGG.outputs = [VGG.layers[9].output]\n",
    "\n",
    "        img = Input(shape = (H_h, H_w, channels))\n",
    "\n",
    "        # Extract image features\n",
    "        img_features = VGG(img)\n",
    "\n",
    "        return Model(img, img_features)\n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    #Generator の実装\n",
    "    def build_generator(self):\n",
    "\n",
    "        #残差ブロックの中身\n",
    "        def residual_block(layer_input, n_filters):\n",
    "            \"\"\"Residual block described in paper\"\"\"\n",
    "            d = Conv2D(n_filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
    "            d = Activation('relu')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Conv2D(n_filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Add()([d, layer_input])\n",
    "            return d\n",
    "\n",
    "        #解像度を2倍にするUpSampling\n",
    "        def deconv2d(layer_input):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input) #\n",
    "            u = Conv2D(120, kernel_size=3, strides=1, padding='same')(u) #\n",
    "            u = Activation('relu')(u)\n",
    "            return u\n",
    "\n",
    "        # Low resolution image input\n",
    "        img_lr = Input(shape = (L_h, L_w, channels))\n",
    "\n",
    "        # Pre-residual block\n",
    "        c1 = Conv2D(60, kernel_size=9, strides=1, padding='same')(img_lr) #\n",
    "        c1 = Activation('relu')(c1)\n",
    "\n",
    "        # Propogate through residual blocks\n",
    "        r = residual_block(c1, self.gf)\n",
    "        for _ in range(self.n_residual_blocks - 1):\n",
    "            r = residual_block(r, self.gf)\n",
    "\n",
    "        #去の残差ブロックと組み合わせる\n",
    "        # Post-residual block\n",
    "        c2 = Conv2D(60, kernel_size=3, strides=1, padding='same')(r) #\n",
    "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
    "        c2 = Add()([c2, c1])\n",
    "\n",
    "        # Upsampling\n",
    "        n = ratio\n",
    "        while(n % 2 == 0):\n",
    "            c2 = deconv2d(c2)\n",
    "            n = n // 2\n",
    "\n",
    "        # Generate high resolution output\n",
    "        gen_hr = Conv2D(channels, kernel_size=9, strides=1, padding='same', activation='tanh')(c2)\n",
    "\n",
    "        return Model(img_lr, gen_hr)\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    #Discriminator の実装\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        \n",
    "        def d_block(layer_input, filters, strides=1, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        # Input img\n",
    "        d0 = Input(shape = (H_h, H_w, channels))\n",
    "        #畳み込み層、チャンネル数を最終的に16倍に\n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2)\n",
    "        d3 = d_block(d2, self.df*2)\n",
    "        d4 = d_block(d3, self.df*2, strides=2)\n",
    "        d5 = d_block(d4, self.df*4)\n",
    "        d6 = d_block(d5, self.df*4, strides=2)\n",
    "        d7 = d_block(d6, self.df*8)\n",
    "        d8 = d_block(d7, self.df*8, strides=2)\n",
    "        #この時点で画像サイズ1/16\n",
    "        d9 = Dense(self.df*16)(d8)\n",
    "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "        validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "        return Model(d0, validity)\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #学習\n",
    "    def train(self, epochs, batch_size, sample_interval=100):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        psnr_file = open('psnr.csv' , 'w+')\n",
    "        psnr_file.close()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ----------------------\n",
    "            #  Train Discriminator\n",
    "            # ----------------------\n",
    "\n",
    "            # Sample images and their conditioning counterparts\n",
    "            HR_images, LR_images = self.data_loader.load_data(batch_size)\n",
    "\n",
    "            # From low res. image generate high res. version\n",
    "            SR_images = self.Generator.predict(LR_images)\n",
    "\n",
    "            valid = np.ones((batch_size,) + self.disc_patch)\n",
    "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "            #Dのloss\n",
    "            # Train the discriminators (original images = real / generated = Fake)\n",
    "            d_loss_real = self.Discriminator.train_on_batch(HR_images, valid)\n",
    "            d_loss_fake = self.Discriminator.train_on_batch(SR_images, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ------------------\n",
    "            #  Train Generator\n",
    "            # ------------------\n",
    "\n",
    "            # Sample images and their conditioning counterparts\n",
    "           \n",
    "            HR_images, LR_images = self.data_loader.load_data(batch_size)\n",
    "\n",
    "            # The generators want the discriminators to label the generated images as real\n",
    "            valid = np.ones((batch_size,) + self.disc_patch)\n",
    "\n",
    "            # Extract ground truth image features using pre-trained VGG19 model\n",
    "            image_features = self.VGG.predict(HR_images)\n",
    "\n",
    "            # Train the generators\n",
    "            g_loss = self.combined.train_on_batch([LR_images, HR_images], [valid, image_features])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            # Plot the progress\n",
    "            print (\"%d time: %s\" % (epoch, elapsed_time))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "                self.Generator.save_weights('srg_weight.h5')\n",
    "                \n",
    "                \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "            \n",
    "    def sample_images(self, epoch):\n",
    "        def denormalize(input_data):\n",
    "            input_data = (input_data + 1) * 127.5\n",
    "            return input_data.astype(np.uint8)\n",
    "        os.makedirs('../../images/images/%s' , exist_ok=True)\n",
    "        r, c = 2, 2\n",
    "\n",
    "        HR_images, LR_images = self.data_loader.load_data(batch_size=2)\n",
    "        SR_images = self.Generator.predict(LR_images)\n",
    "\n",
    "        LR_images = denormalize(LR_images)\n",
    "        SR_images = denormalize(SR_images)\n",
    "        HR_images = denormalize(HR_images)\n",
    "\n",
    "        def psnr_calc(img1: np.ndarray, img2: np.ndarray, upscaling=2):\n",
    "            def convert(img):\n",
    "                return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            def extract_y(image: np.ndarray) -> np.ndarray:\n",
    "                if image.ndim == 2:\n",
    "                    return image\n",
    "                image = image.astype(np.int32)\n",
    "                return ((image[:, :, 2] * 65.481 / 255.\n",
    "                          + image[:, :, 1] * 128.553 / 255.\n",
    "                          + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n",
    "\n",
    "\n",
    "            def psnr(img1, img2):\n",
    "                mse = np.mean((img1 - img2) ** 2)\n",
    "                if mse == 0:\n",
    "                    return 100\n",
    "                PIXEL_MAX = 255.0\n",
    "                return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n",
    "  \n",
    "            img1_conv=convert(img1)\n",
    "            img2_conv=convert(img2)\n",
    "  \n",
    "            # BGR -> YCrCb\n",
    "            # 画像はcv2.imreadで読まれている前提 [0, 255]\n",
    "            y1 = extract_y(img1_conv)\n",
    "            y2 = extract_y(img2_conv)\n",
    "            # 周囲のcropping\n",
    "            # assert y1.shape == y2.shape\n",
    "            h, w = y1.shape\n",
    "            cr = upscaling\n",
    "            cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "            cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "\n",
    "            # psnr\n",
    "            psnr_val = psnr(cropped_y1, cropped_y2)\n",
    "            return psnr_val\n",
    "        \n",
    "        \n",
    "        # Save generated images and the high resolution originals\n",
    "        titles = ['Generated', 'Original']\n",
    "\n",
    "        cv2.imwrite(\"../../images/images/hreal_img_0.png\",HR_images[0])\n",
    "        cv2.imwrite(\"../../images/images/hreal_img_1.png\",HR_images[1])\n",
    "        cv2.imwrite(\"../../images/images/lreal_img_0.png\",LR_images[0])\n",
    "        cv2.imwrite(\"../../images/images/lreal_img_1.png\",LR_images[1])\n",
    "        # size=(480,480)\n",
    "\n",
    "        for i in range(r):\n",
    "            psnr = psnr_calc(HR_images[i],SR_images[i])\n",
    "            print(psnr)\n",
    "            data =[epoch,psnr]\n",
    "            psnr_file = open('psnr.csv' , 'a')\n",
    "            writer = csv.writer(psnr_file, lineterminator='\\n')  \n",
    "            writer.writerow(data)\n",
    "            psnr_file.close()\n",
    "            cv2.imwrite(\"../../images/images/{}_{}img_pred.png\".format(epoch,i),SR_images[i])\n",
    "            \n",
    "            \n",
    "    #------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 time: 0:00:29.698188\n",
      "15.38781255866509\n",
      "16.596670663728652\n",
      "1 time: 0:01:59.390437\n",
      "2 time: 0:02:00.012322\n",
      "3 time: 0:02:00.637394\n",
      "4 time: 0:02:01.270736\n",
      "5 time: 0:02:01.884764\n",
      "6 time: 0:02:02.507765\n",
      "7 time: 0:02:03.134840\n",
      "8 time: 0:02:03.753403\n",
      "9 time: 0:02:04.372472\n",
      "10 time: 0:02:05.045083\n",
      "11 time: 0:02:05.674440\n",
      "12 time: 0:02:06.279991\n",
      "13 time: 0:02:06.916852\n",
      "14 time: 0:02:07.552796\n",
      "15 time: 0:02:08.170124\n",
      "16 time: 0:02:08.798750\n",
      "17 time: 0:02:09.424801\n",
      "18 time: 0:02:10.038863\n",
      "19 time: 0:02:10.656929\n",
      "20 time: 0:02:11.287057\n",
      "21 time: 0:02:11.888603\n",
      "22 time: 0:02:12.519088\n",
      "23 time: 0:02:13.149039\n",
      "24 time: 0:02:13.767074\n",
      "25 time: 0:02:14.384119\n",
      "26 time: 0:02:15.011197\n",
      "27 time: 0:02:15.633265\n",
      "28 time: 0:02:16.239723\n",
      "29 time: 0:02:16.873299\n",
      "30 time: 0:02:17.499869\n",
      "31 time: 0:02:18.116430\n",
      "32 time: 0:02:18.747402\n",
      "33 time: 0:02:19.375402\n",
      "34 time: 0:02:19.984956\n",
      "35 time: 0:02:20.613031\n",
      "36 time: 0:02:21.242604\n",
      "37 time: 0:02:21.857063\n",
      "38 time: 0:02:22.482938\n",
      "39 time: 0:02:23.103540\n",
      "40 time: 0:02:23.724104\n",
      "41 time: 0:02:24.337662\n",
      "42 time: 0:02:24.965271\n",
      "43 time: 0:02:25.594303\n",
      "44 time: 0:02:26.206751\n",
      "45 time: 0:02:26.834666\n",
      "46 time: 0:02:27.462953\n",
      "47 time: 0:02:28.066502\n",
      "48 time: 0:02:28.698715\n",
      "49 time: 0:02:29.339156\n",
      "50 time: 0:02:29.958860\n",
      "17.09379436967709\n",
      "29.06162284030121\n",
      "51 time: 0:02:31.026852\n",
      "52 time: 0:02:31.654639\n",
      "53 time: 0:02:32.272200\n",
      "54 time: 0:02:32.906281\n",
      "55 time: 0:02:33.537244\n",
      "56 time: 0:02:34.149249\n",
      "57 time: 0:02:34.773817\n",
      "58 time: 0:02:35.407243\n",
      "59 time: 0:02:36.016777\n",
      "60 time: 0:02:36.648349\n",
      "61 time: 0:02:37.274141\n",
      "62 time: 0:02:37.889968\n",
      "63 time: 0:02:38.521051\n",
      "64 time: 0:02:39.154055\n",
      "65 time: 0:02:39.770020\n",
      "66 time: 0:02:40.425537\n",
      "67 time: 0:02:41.048272\n",
      "68 time: 0:02:41.675842\n",
      "69 time: 0:02:42.290210\n",
      "70 time: 0:02:42.921787\n",
      "71 time: 0:02:43.543351\n",
      "72 time: 0:02:44.151407\n",
      "73 time: 0:02:44.774974\n",
      "74 time: 0:02:45.405240\n",
      "75 time: 0:02:46.020394\n",
      "76 time: 0:02:46.649965\n",
      "77 time: 0:02:47.270531\n",
      "78 time: 0:02:47.885460\n",
      "79 time: 0:02:48.516033\n",
      "80 time: 0:02:49.148113\n",
      "81 time: 0:02:49.773682\n",
      "82 time: 0:02:50.393245\n",
      "83 time: 0:02:51.024820\n",
      "84 time: 0:02:51.639379\n",
      "85 time: 0:02:52.254406\n",
      "86 time: 0:02:52.887983\n",
      "87 time: 0:02:53.512055\n",
      "88 time: 0:02:54.119611\n",
      "89 time: 0:02:54.749356\n",
      "90 time: 0:02:55.370921\n",
      "91 time: 0:02:55.992249\n",
      "92 time: 0:02:56.617321\n",
      "93 time: 0:02:57.242392\n",
      "94 time: 0:02:57.855674\n",
      "95 time: 0:02:58.489955\n",
      "96 time: 0:02:59.108517\n",
      "97 time: 0:02:59.730722\n",
      "98 time: 0:03:00.342277\n",
      "99 time: 0:03:00.978246\n",
      "100 time: 0:03:01.608820\n",
      "15.30965554028815\n",
      "13.847103436853214\n",
      "101 time: 0:03:02.668567\n",
      "102 time: 0:03:03.294136\n",
      "103 time: 0:03:03.908083\n",
      "104 time: 0:03:04.537987\n",
      "105 time: 0:03:05.166163\n",
      "106 time: 0:03:05.777720\n",
      "107 time: 0:03:06.395280\n",
      "108 time: 0:03:07.025214\n",
      "109 time: 0:03:07.644776\n",
      "110 time: 0:03:08.259595\n",
      "111 time: 0:03:08.894679\n",
      "112 time: 0:03:09.520224\n",
      "113 time: 0:03:10.128776\n",
      "114 time: 0:03:10.759092\n",
      "115 time: 0:03:11.391968\n",
      "116 time: 0:03:12.011931\n",
      "117 time: 0:03:12.639997\n",
      "118 time: 0:03:13.273821\n",
      "119 time: 0:03:13.883375\n",
      "120 time: 0:03:14.507943\n",
      "121 time: 0:03:15.139015\n",
      "122 time: 0:03:15.759580\n",
      "123 time: 0:03:16.377072\n",
      "124 time: 0:03:17.004642\n",
      "125 time: 0:03:17.634197\n",
      "126 time: 0:03:18.245753\n",
      "127 time: 0:03:18.865316\n",
      "128 time: 0:03:19.494610\n",
      "129 time: 0:03:20.109573\n",
      "130 time: 0:03:20.737052\n",
      "131 time: 0:03:21.356614\n",
      "132 time: 0:03:21.966169\n",
      "133 time: 0:03:22.598145\n",
      "134 time: 0:03:23.225977\n",
      "135 time: 0:03:23.830527\n",
      "136 time: 0:03:24.453092\n",
      "137 time: 0:03:25.087175\n",
      "138 time: 0:03:25.704239\n",
      "139 time: 0:03:26.311989\n",
      "140 time: 0:03:26.941898\n",
      "141 time: 0:03:27.563968\n",
      "142 time: 0:03:28.182082\n",
      "143 time: 0:03:28.803647\n",
      "144 time: 0:03:29.424212\n",
      "145 time: 0:03:30.034199\n",
      "146 time: 0:03:30.659360\n",
      "147 time: 0:03:31.284032\n",
      "148 time: 0:03:31.888638\n",
      "149 time: 0:03:32.508201\n",
      "150 time: 0:03:33.131768\n",
      "23.94659212301026\n",
      "21.068808614701\n",
      "151 time: 0:03:34.532337\n",
      "152 time: 0:03:35.160533\n",
      "153 time: 0:03:35.778107\n",
      "154 time: 0:03:36.412299\n",
      "155 time: 0:03:37.043874\n",
      "156 time: 0:03:37.668814\n",
      "157 time: 0:03:38.288234\n",
      "158 time: 0:03:38.909325\n",
      "159 time: 0:03:39.534399\n",
      "160 time: 0:03:40.149366\n",
      "161 time: 0:03:40.778442\n",
      "162 time: 0:03:41.406013\n",
      "163 time: 0:03:42.014566\n",
      "164 time: 0:03:42.639638\n",
      "165 time: 0:03:43.260203\n",
      "166 time: 0:03:43.871263\n",
      "167 time: 0:03:44.492828\n",
      "168 time: 0:03:45.124304\n",
      "169 time: 0:03:45.739864\n",
      "170 time: 0:03:46.355424\n",
      "171 time: 0:03:46.977990\n",
      "172 time: 0:03:47.604063\n",
      "173 time: 0:03:48.210120\n",
      "174 time: 0:03:48.843111\n",
      "175 time: 0:03:49.469681\n",
      "176 time: 0:03:50.084716\n",
      "177 time: 0:03:50.708281\n",
      "178 time: 0:03:51.342665\n",
      "179 time: 0:03:51.953220\n",
      "180 time: 0:03:52.573784\n",
      "181 time: 0:03:53.207778\n",
      "182 time: 0:03:53.823727\n",
      "183 time: 0:03:54.443291\n",
      "184 time: 0:03:55.071862\n",
      "185 time: 0:03:55.699355\n",
      "186 time: 0:03:56.312418\n",
      "187 time: 0:03:56.944994\n",
      "188 time: 0:03:57.575778\n",
      "189 time: 0:03:58.180328\n",
      "190 time: 0:03:58.803401\n",
      "191 time: 0:03:59.430966\n",
      "192 time: 0:04:00.040068\n",
      "193 time: 0:04:00.665141\n",
      "194 time: 0:04:01.290710\n",
      "195 time: 0:04:01.901266\n",
      "196 time: 0:04:02.523831\n",
      "197 time: 0:04:03.152259\n",
      "198 time: 0:04:03.761811\n",
      "199 time: 0:04:04.377370\n",
      "200 time: 0:04:04.997935\n",
      "22.714795453913993\n",
      "19.179297755904855\n",
      "201 time: 0:04:06.047574\n",
      "202 time: 0:04:06.673143\n",
      "203 time: 0:04:07.304221\n",
      "204 time: 0:04:07.912269\n",
      "205 time: 0:04:08.540345\n",
      "206 time: 0:04:09.172367\n",
      "207 time: 0:04:09.787431\n",
      "208 time: 0:04:10.406994\n",
      "209 time: 0:04:11.037272\n",
      "210 time: 0:04:11.660839\n",
      "211 time: 0:04:12.274398\n",
      "212 time: 0:04:12.905972\n",
      "213 time: 0:04:13.528538\n",
      "214 time: 0:04:14.143097\n",
      "215 time: 0:04:14.764662\n",
      "216 time: 0:04:15.387735\n",
      "217 time: 0:04:15.999896\n",
      "218 time: 0:04:16.621998\n",
      "219 time: 0:04:17.252832\n",
      "220 time: 0:04:17.861385\n",
      "221 time: 0:04:18.489475\n",
      "222 time: 0:04:19.120048\n",
      "223 time: 0:04:19.730603\n",
      "224 time: 0:04:20.340158\n",
      "225 time: 0:04:20.971691\n",
      "226 time: 0:04:21.594257\n",
      "227 time: 0:04:22.207255\n",
      "228 time: 0:04:22.831823\n",
      "229 time: 0:04:23.453389\n",
      "230 time: 0:04:24.066947\n",
      "231 time: 0:04:24.690513\n",
      "232 time: 0:04:25.321087\n",
      "233 time: 0:04:25.923138\n",
      "234 time: 0:04:26.542735\n",
      "235 time: 0:04:27.172308\n",
      "236 time: 0:04:27.778859\n",
      "237 time: 0:04:28.411783\n",
      "238 time: 0:04:29.044359\n",
      "239 time: 0:04:29.666925\n",
      "240 time: 0:04:30.272981\n",
      "241 time: 0:04:30.897052\n",
      "242 time: 0:04:31.521620\n",
      "243 time: 0:04:32.130174\n",
      "244 time: 0:04:32.761081\n",
      "245 time: 0:04:33.384648\n",
      "246 time: 0:04:33.990793\n",
      "247 time: 0:04:34.612863\n",
      "248 time: 0:04:35.245439\n",
      "249 time: 0:04:35.854482\n",
      "250 time: 0:04:36.473045\n",
      "16.8721941415073\n",
      "20.91897994908676\n",
      "251 time: 0:04:37.531237\n",
      "252 time: 0:04:38.145206\n",
      "253 time: 0:04:38.780784\n",
      "254 time: 0:04:39.408300\n",
      "255 time: 0:04:40.020857\n",
      "256 time: 0:04:40.639420\n",
      "257 time: 0:04:41.268685\n",
      "258 time: 0:04:41.888683\n",
      "259 time: 0:04:42.513462\n",
      "260 time: 0:04:43.145903\n",
      "261 time: 0:04:43.757458\n",
      "262 time: 0:04:44.374019\n",
      "263 time: 0:04:45.006098\n",
      "264 time: 0:04:45.627664\n",
      "265 time: 0:04:46.242727\n",
      "266 time: 0:04:46.865293\n",
      "267 time: 0:04:47.485858\n",
      "268 time: 0:04:48.097919\n",
      "269 time: 0:04:48.716480\n",
      "270 time: 0:04:49.340135\n",
      "271 time: 0:04:49.956598\n",
      "272 time: 0:04:50.578706\n",
      "273 time: 0:04:51.207277\n",
      "274 time: 0:04:51.815831\n",
      "275 time: 0:04:52.441036\n",
      "276 time: 0:04:53.064603\n",
      "277 time: 0:04:53.695046\n",
      "278 time: 0:04:54.308603\n",
      "279 time: 0:04:54.930166\n",
      "280 time: 0:04:55.552732\n",
      "281 time: 0:04:56.162793\n",
      "282 time: 0:04:56.786360\n",
      "283 time: 0:04:57.416934\n",
      "284 time: 0:04:58.027005\n",
      "285 time: 0:04:58.656232\n",
      "286 time: 0:04:59.285804\n",
      "287 time: 0:04:59.898669\n",
      "288 time: 0:05:00.526241\n",
      "289 time: 0:05:01.158318\n",
      "290 time: 0:05:01.775388\n",
      "291 time: 0:05:02.393947\n",
      "292 time: 0:05:03.023024\n",
      "293 time: 0:05:03.645592\n",
      "294 time: 0:05:04.259616\n",
      "295 time: 0:05:04.897633\n",
      "296 time: 0:05:05.530209\n",
      "297 time: 0:05:06.145132\n",
      "298 time: 0:05:06.772208\n",
      "299 time: 0:05:07.397778\n",
      "300 time: 0:05:08.018756\n",
      "20.961023426988184\n",
      "22.308635528955996\n",
      "301 time: 0:05:09.090091\n",
      "302 time: 0:05:09.711073\n",
      "303 time: 0:05:10.327633\n",
      "304 time: 0:05:10.953707\n",
      "305 time: 0:05:11.581278\n",
      "306 time: 0:05:12.190336\n",
      "307 time: 0:05:12.815906\n",
      "308 time: 0:05:13.442475\n",
      "309 time: 0:05:14.054534\n",
      "310 time: 0:05:14.675098\n",
      "311 time: 0:05:15.307674\n",
      "312 time: 0:05:15.913729\n",
      "313 time: 0:05:16.540805\n",
      "314 time: 0:05:17.166374\n",
      "315 time: 0:05:17.777432\n",
      "316 time: 0:05:18.393992\n",
      "317 time: 0:05:19.022406\n",
      "318 time: 0:05:19.651269\n",
      "319 time: 0:05:20.264324\n",
      "320 time: 0:05:20.886394\n",
      "321 time: 0:05:21.508960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 time: 0:05:22.119517\n",
      "323 time: 0:05:22.738583\n",
      "324 time: 0:05:23.368792\n",
      "325 time: 0:05:23.983743\n",
      "326 time: 0:05:24.605308\n",
      "327 time: 0:05:25.235882\n",
      "328 time: 0:05:25.841936\n",
      "329 time: 0:05:26.464502\n",
      "330 time: 0:05:27.089071\n",
      "331 time: 0:05:27.712173\n",
      "332 time: 0:05:28.335222\n",
      "333 time: 0:05:28.961330\n",
      "334 time: 0:05:29.588329\n",
      "335 time: 0:05:30.198885\n",
      "336 time: 0:05:30.822452\n",
      "337 time: 0:05:31.452530\n",
      "338 time: 0:05:32.069706\n",
      "339 time: 0:05:32.702283\n",
      "340 time: 0:05:33.324847\n",
      "341 time: 0:05:33.930903\n",
      "342 time: 0:05:34.554948\n",
      "343 time: 0:05:35.175512\n",
      "344 time: 0:05:35.785066\n",
      "345 time: 0:05:36.405631\n",
      "346 time: 0:05:37.030682\n",
      "347 time: 0:05:37.651246\n",
      "348 time: 0:05:38.259304\n",
      "349 time: 0:05:38.880869\n",
      "350 time: 0:05:39.503940\n",
      "22.881361691762034\n",
      "23.706581853811542\n",
      "351 time: 0:05:40.555922\n",
      "352 time: 0:05:41.190630\n",
      "353 time: 0:05:41.799183\n",
      "354 time: 0:05:42.421900\n",
      "355 time: 0:05:43.046468\n",
      "356 time: 0:05:43.665536\n",
      "357 time: 0:05:44.281096\n",
      "358 time: 0:05:44.903166\n",
      "359 time: 0:05:45.523730\n",
      "360 time: 0:05:46.136756\n",
      "361 time: 0:05:46.757584\n",
      "362 time: 0:05:47.385154\n",
      "363 time: 0:05:47.996172\n",
      "364 time: 0:05:48.626745\n",
      "365 time: 0:05:49.248817\n",
      "366 time: 0:05:49.851365\n",
      "367 time: 0:05:50.475932\n",
      "368 time: 0:05:51.099501\n",
      "369 time: 0:05:51.722414\n",
      "370 time: 0:05:52.337975\n",
      "371 time: 0:05:52.960540\n",
      "372 time: 0:05:53.589676\n",
      "373 time: 0:05:54.205237\n",
      "374 time: 0:05:54.840814\n",
      "375 time: 0:05:55.474391\n",
      "376 time: 0:05:56.090951\n",
      "377 time: 0:05:56.715519\n",
      "378 time: 0:05:57.342089\n",
      "379 time: 0:05:57.956648\n",
      "380 time: 0:05:58.579367\n",
      "381 time: 0:05:59.205937\n",
      "382 time: 0:05:59.814490\n",
      "383 time: 0:06:00.429049\n",
      "384 time: 0:06:01.052616\n",
      "385 time: 0:06:01.669177\n",
      "386 time: 0:06:02.278731\n",
      "387 time: 0:06:02.902298\n",
      "388 time: 0:06:03.522863\n",
      "389 time: 0:06:04.140032\n",
      "390 time: 0:06:04.774608\n",
      "391 time: 0:06:05.394172\n",
      "392 time: 0:06:06.003726\n",
      "393 time: 0:06:06.623289\n",
      "394 time: 0:06:07.245856\n",
      "395 time: 0:06:07.852407\n",
      "396 time: 0:06:08.474973\n",
      "397 time: 0:06:09.107549\n",
      "398 time: 0:06:09.721107\n",
      "399 time: 0:06:10.336666\n",
      "400 time: 0:06:10.959738\n",
      "24.732110286806005\n",
      "21.42081487121116\n",
      "401 time: 0:06:12.014468\n",
      "402 time: 0:06:12.639542\n",
      "403 time: 0:06:13.269114\n",
      "404 time: 0:06:13.872167\n",
      "405 time: 0:06:14.501739\n",
      "406 time: 0:06:15.137604\n",
      "407 time: 0:06:15.779035\n",
      "408 time: 0:06:16.402107\n",
      "409 time: 0:06:17.038982\n",
      "410 time: 0:06:17.665055\n",
      "411 time: 0:06:18.275611\n",
      "412 time: 0:06:18.905183\n",
      "413 time: 0:06:19.536484\n",
      "414 time: 0:06:20.147039\n",
      "415 time: 0:06:20.776116\n",
      "416 time: 0:06:21.407168\n",
      "417 time: 0:06:22.020542\n",
      "418 time: 0:06:22.654118\n",
      "419 time: 0:06:23.280192\n",
      "420 time: 0:06:23.886744\n",
      "421 time: 0:06:24.511297\n",
      "422 time: 0:06:25.140250\n",
      "423 time: 0:06:25.749308\n",
      "424 time: 0:06:26.369872\n",
      "425 time: 0:06:27.003731\n",
      "426 time: 0:06:27.626300\n",
      "427 time: 0:06:28.234851\n",
      "428 time: 0:06:28.859419\n",
      "429 time: 0:06:29.486494\n",
      "430 time: 0:06:30.096647\n",
      "431 time: 0:06:30.726335\n",
      "432 time: 0:06:31.351764\n",
      "433 time: 0:06:31.957315\n",
      "434 time: 0:06:32.579881\n",
      "435 time: 0:06:33.211455\n",
      "436 time: 0:06:33.822011\n",
      "437 time: 0:06:34.445083\n",
      "438 time: 0:06:35.075656\n",
      "439 time: 0:06:35.694219\n",
      "440 time: 0:06:36.307777\n",
      "441 time: 0:06:36.941858\n",
      "442 time: 0:06:37.571430\n",
      "443 time: 0:06:38.182987\n",
      "444 time: 0:06:38.808555\n",
      "445 time: 0:06:39.438128\n",
      "446 time: 0:06:40.047682\n",
      "447 time: 0:06:40.673752\n",
      "448 time: 0:06:41.298824\n",
      "449 time: 0:06:41.904374\n",
      "450 time: 0:06:42.528942\n",
      "19.888658403135913\n",
      "22.299875816025853\n",
      "451 time: 0:06:43.608895\n",
      "452 time: 0:06:44.217449\n",
      "453 time: 0:06:44.849000\n",
      "454 time: 0:06:45.472626\n",
      "455 time: 0:06:46.087904\n",
      "456 time: 0:06:46.711689\n",
      "457 time: 0:06:47.338259\n",
      "458 time: 0:06:47.947108\n",
      "459 time: 0:06:48.571678\n",
      "460 time: 0:06:49.198246\n",
      "461 time: 0:06:49.809802\n",
      "462 time: 0:06:50.426686\n",
      "463 time: 0:06:51.052760\n",
      "464 time: 0:06:51.672324\n",
      "465 time: 0:06:52.279878\n",
      "466 time: 0:06:52.917465\n",
      "467 time: 0:06:53.546412\n",
      "468 time: 0:06:54.167679\n",
      "469 time: 0:06:54.792805\n",
      "470 time: 0:06:55.419377\n",
      "471 time: 0:06:56.025432\n",
      "472 time: 0:06:56.656006\n",
      "473 time: 0:06:57.279077\n",
      "474 time: 0:06:57.893637\n",
      "475 time: 0:06:58.520710\n",
      "476 time: 0:06:59.145330\n",
      "477 time: 0:06:59.759889\n",
      "478 time: 0:07:00.378897\n",
      "479 time: 0:07:01.004970\n",
      "480 time: 0:07:01.634503\n",
      "481 time: 0:07:02.253066\n",
      "482 time: 0:07:02.879140\n",
      "483 time: 0:07:03.506710\n",
      "484 time: 0:07:04.114768\n",
      "485 time: 0:07:04.738335\n",
      "486 time: 0:07:05.361405\n",
      "487 time: 0:07:05.981339\n",
      "488 time: 0:07:06.604906\n",
      "489 time: 0:07:07.235251\n",
      "490 time: 0:07:07.842330\n",
      "491 time: 0:07:08.462397\n",
      "492 time: 0:07:09.095973\n",
      "493 time: 0:07:09.716526\n",
      "494 time: 0:07:10.332086\n",
      "495 time: 0:07:10.958158\n",
      "496 time: 0:07:11.587590\n",
      "497 time: 0:07:12.199197\n",
      "498 time: 0:07:12.821763\n",
      "499 time: 0:07:13.454339\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = SRGAN()\n",
    "    gan.train(epochs=500, batch_size=1, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
