{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Dense, Add, Activation, Reshape, Permute, Flatten\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG19\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ratio = 4\n",
    "LR_shape = (120, 160, 3)\n",
    "\n",
    "L_h, L_w, channels = LR_shape\n",
    "H_h = L_h * ratio\n",
    "H_w = L_w * ratio\n",
    "# HR_shape = np.array([H_h, H_w, c])\n",
    "HR_shape = (H_h, H_w, channels)\n",
    "\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def save_images(epoch, hr_img, lr_img, sr_img):\n",
    "    hr_img = denormalize(hr_img)\n",
    "    lr_img = denormalize(lr_img)\n",
    "    sr_img = denormalize(sr_img)\n",
    "    \n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_HRimage.png\", hr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_LRimage.png\", lr_img)\n",
    "    cv2.imwrite(\"../../images/output/\" + str(epoch+1) + \"_SRimage.png\", sr_img)\n",
    "\n",
    "    \n",
    "def calc_psnr(img1: np.ndarray, img2: np.ndarray):\n",
    "    def convert(img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    def extract_y(image: np.ndarray) -> np.ndarray:\n",
    "        if image.ndim == 2:\n",
    "            return image\n",
    "        image = image.astype(np.int32)\n",
    "        return ((image[:, :, 2] * 65.481 / 255.\n",
    "                  + image[:, :, 1] * 128.553 / 255.\n",
    "                  + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n",
    "\n",
    "\n",
    "    def psnr(img1, img2):\n",
    "        mse = np.mean((img1 - img2) ** 2)\n",
    "        if mse == 0:\n",
    "            return 100\n",
    "        PIXEL_MAX = 255.0\n",
    "        return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n",
    "\n",
    "    img1_conv=convert(img1)\n",
    "    img2_conv=convert(img2)\n",
    "\n",
    "    # BGR -> YCrCb\n",
    "    # 画像はcv2.imreadで読まれている前提 [0, 255]\n",
    "    y1 = extract_y(img1_conv)\n",
    "    y2 = extract_y(img2_conv)\n",
    "    # 周囲のcropping\n",
    "    # assert y1.shape == y2.shape\n",
    "    h, w = y1.shape\n",
    "    cr = ratio\n",
    "    cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "    cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "\n",
    "    # psnr\n",
    "    psnr_val = psnr(cropped_y1, cropped_y2)\n",
    "    return psnr_val\n",
    "\n",
    "\n",
    "def load_data(batch_size):\n",
    "\n",
    "    files = glob.glob(\"../../images/train/*.png\", recursive=True)\n",
    "    batch_images = random.sample(files, batch_size)\n",
    "\n",
    "    hr_imgs = []\n",
    "    lr_imgs = []\n",
    "    for img_path in batch_images:\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        hr_img = img.resize((H_w, H_h))  #(64, 64)\n",
    "        lr_img = img.resize((L_w, L_h))\n",
    "        hr_img = np.array(hr_img)\n",
    "        #img_hr = (img_hr - 127.5) / 127.5\n",
    "        lr_img = np.array(lr_img)\n",
    "        #img_lr = (img_lr - 127.5) / 127.5\n",
    "\n",
    "        hr_imgs.append(hr_img)\n",
    "        lr_imgs.append(lr_img)\n",
    "\n",
    "    hr_imgs = np.array(hr_imgs) / 127.5 - 1.\n",
    "    lr_imgs = np.array(lr_imgs) / 127.5 - 1.\n",
    "\n",
    "    return hr_imgs, lr_imgs\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pixel_shuffle(in_map, h, w, c):#((120, 160, 12), 120, 160, 3)\n",
    "    \n",
    "    x = Reshape((h, w, 2, 2, c))(in_map)\n",
    "    x = Permute((3, 1, 4, 2, 5))(x)\n",
    "    out_map = Reshape((2 * h, 2 * w, c))(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def upsampling(in_map, h, w, c):#((, 120, 160, 3), g:120, 160 , 64\n",
    "    \n",
    "    x = Conv2D(filters = 4 * c, \n",
    "                     kernel_size = 3,\n",
    "                     strides = 1,\n",
    "                     padding = \"same\")(in_map)# x: 120, 160, 12\n",
    "    x = pixel_shuffle(x, h, w, c)# ( , 120, 160, 3)\n",
    "    out_map = PReLU()(x)\n",
    "    \n",
    "    return out_map\n",
    "\n",
    "\n",
    "def residual_block(in_map):\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(in_map)\n",
    "    x = LeakyReLU(alpha = 0.01)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out_map = Add()([x, in_map])\n",
    "    return out_map\n",
    "\n",
    "\n",
    "def d_block(in_map, filters, kernel_size, strides, padding):\n",
    "    d = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding)(in_map)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    d = BatchNormalization(momentum = 0.8)(d)\n",
    "    return d\n",
    "\n",
    "\n",
    "def deconv2d(layer_input):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input) #\n",
    "            u = Conv2D(120, kernel_size=3, strides=1, padding='same')(u) #\n",
    "            u = Activation('relu')(u)\n",
    "            return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    middle = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(input_img)\n",
    "    middle = LeakyReLU(alpha = 0.01)(middle)\n",
    "    \n",
    "    g = residual_block(middle)\n",
    "    for _ in range(15):\n",
    "        g = residual_block(g)\n",
    "\n",
    "    g = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = Add()([g, middle])\n",
    "\n",
    "    n = ratio\n",
    "    i = 1\n",
    "    while(n % 2 == 0):\n",
    "        g = deconv2d(g)\n",
    "#         g = upsampling(g, L_h * i, L_w * i, channels)#(g, 120, 160, 3), g:120, 160 , 64\n",
    "#         i = i * 2\n",
    "        n = n // 2\n",
    "\n",
    "    output_img = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(g)\n",
    "\n",
    "    return Model(input_img, output_img)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    input_img = Input(shape = HR_shape)\n",
    "    \n",
    "    d = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(input_img)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = d_block(d, filters = 64, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 128, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 256, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 1, padding = \"same\")\n",
    "    d = d_block(d, filters = 512, kernel_size = 3, strides = 2, padding = \"same\")\n",
    "#     d = Flatten()(d)\n",
    "    d = Dense(1024)(d)\n",
    "    d = LeakyReLU(alpha = 0.2)(d)\n",
    "    output = Dense(1, activation = \"sigmoid\")(d)\n",
    "\n",
    "    return Model(input_img, output)\n",
    "\n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def build_vgg():\n",
    "    vgg = VGG19(include_top = False)\n",
    "    return Model(vgg.input, vgg.layers[9].output)\n",
    "    \n",
    "#------------------------------------------------------------------------#\n",
    "\n",
    "def combined(generator, discriminator, vgg):\n",
    "    input_img = Input(shape = LR_shape)\n",
    "    fake_img = generator(input_img)\n",
    "    \n",
    "    validity = discriminator(fake_img)\n",
    "    features = vgg(fake_img)\n",
    "    \n",
    "    return Model(input_img, [validity, features])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "epochs_checkpoint = []\n",
    "psnr = []\n",
    "\n",
    "def train(epochs, batch_size, interval):\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    real = np.ones((batch_size,) + (H_h // 16, H_w // 16, 1))\n",
    "    fake = np.zeros((batch_size,) + (H_h // 16, H_w // 16, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        real_imgs, lr_imgs = load_data(batch_size)\n",
    "        fake_imgs = generator.predict(lr_imgs)\n",
    "        \n",
    "        #Dの訓練\n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        #Gの訓練\n",
    "        vgg_features = vgg.predict(real_imgs)\n",
    "        g_loss = srgan.train_on_batch(lr_imgs, [real, vgg_features])\n",
    "        \n",
    "        time = datetime.datetime.now() - start_time\n",
    "        print(\"%d time: %s\" % (epoch+1, time))\n",
    "        \n",
    "        if (epoch+1) % interval == 0:\n",
    "            print(\"epoch: %d\" % (epoch+1))\n",
    "            losses.append((d_loss, g_loss))\n",
    "            epochs_checkpoint.append(epoch+1)\n",
    "            save_images(epoch, real_imgs[0], lr_imgs[0], fake_imgs[0])\n",
    "#             psnr.append(calc_psnr(real_imgs[0], fake_imgs[0]))\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    generator.save_weights(\"../../weights/\" +  now.strftime('%Y%m%d_%H%M') + \"_g_weight.h5\")\n",
    "    discriminator.save_weights(\"../../weights/\" +  now.strftime('%Y%m%d_%H%M') + \"_d_weight.h5\")\n",
    "    srgan.save_weights(\"../../weights/\" +  now.strftime('%Y%m%d_%H%M') + \"_srgan_weight.h5\")\n",
    "    print(\"save weights\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train(epochs, batch_size, interval):\n",
    "    start_time = datetime.datetime.now()\n",
    "    generator.compile(loss = \"mse\",\n",
    "                      optimizer = optimizer,\n",
    "                      metrics = [\"accuracy\"])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        real_imgs, lr_imgs = load_data(batch_size)\n",
    "        fake_imgs = generator.predict(lr_imgs)\n",
    "        \n",
    "        #Gの訓練\n",
    "        g_loss = generator.train_on_batch(lr_imgs, real_imgs)\n",
    "        \n",
    "        time = datetime.datetime.now() - start_time\n",
    "        print(\"%d time: %s\" % (epoch+1, time))\n",
    "        \n",
    "        if (epoch+1) % interval == 0:\n",
    "            save_images(epoch, real_imgs[0], lr_imgs[0], fake_imgs[0])\n",
    "\n",
    "    generator.save_weights(\"generator_first_weight.h5\")\n",
    "    print(\"save seights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 480, 640, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 480, 640, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 240, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 320, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 240, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 240, 320, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 240, 320, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 120, 160, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 120, 160, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 120, 160, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 120, 160, 256)     295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 120, 160, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 160, 256)     1024      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 60, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 80, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 80, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 60, 80, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 80, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 40, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 40, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 40, 1024)      525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 40, 1024)      0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 40, 1)         1025      \n",
      "=================================================================\n",
      "Total params: 5,219,137\n",
      "Trainable params: 5,215,425\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1615: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 120, 160, 64)      15616     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_1 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_2 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_3 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_4 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_5 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_6 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_7 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_8 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_9 (Add)                  (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_10 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_11 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_12 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_13 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_14 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_15 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_16 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 120, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 120, 160, 64)      256       \n",
      "_________________________________________________________________\n",
      "add_17 (Add)                 (None, 120, 160, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 240, 320, 120)     69240     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 240, 320, 120)     0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 480, 640, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 480, 640, 120)     129720    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 480, 640, 120)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 480, 640, 3)       29163     \n",
      "=================================================================\n",
      "Total params: 1,470,811\n",
      "Trainable params: 1,466,587\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------\n",
    "# メインプログラム\n",
    "#------------------------------------\n",
    "\n",
    "#Discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss = \"mse\",\n",
    "                      optimizer = optimizer,\n",
    "                      metrics = [\"accuracy\"])\n",
    "discriminator.summary()\n",
    "\n",
    "#Generator どちらかを使う\n",
    "#新規作成\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "#読み込み\n",
    "# generator = load_model(\"generator_first_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator_train(epochs = 10000, batch_size = 1, interval = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:146: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 120, 160, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 480, 640, 3)   1470811                                      \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 30, 40, 1)     5219137                                      \n",
      "____________________________________________________________________________________________________\n",
      "model_3 (Model)                  multiple              1735488                                      \n",
      "====================================================================================================\n",
      "Total params: 8,425,436\n",
      "Trainable params: 8,417,500\n",
      "Non-trainable params: 7,936\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = build_vgg()\n",
    "vgg.trainable = False\n",
    "discriminator.trainable = False\n",
    "srgan = combined(generator, discriminator, vgg)\n",
    "srgan.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "srgan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\robotics\\anaconda3\\envs\\faster_rcnn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:521: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "1 time: 0:00:22.159081\n",
      "2 time: 0:00:23.297567\n",
      "3 time: 0:00:24.394143\n",
      "4 time: 0:00:25.514722\n",
      "5 time: 0:00:26.626862\n",
      "6 time: 0:00:27.752389\n",
      "7 time: 0:00:28.857541\n",
      "8 time: 0:00:29.971573\n",
      "9 time: 0:00:31.098717\n",
      "10 time: 0:00:32.190206\n",
      "11 time: 0:00:33.331743\n",
      "12 time: 0:00:34.440101\n",
      "13 time: 0:00:35.563122\n",
      "14 time: 0:00:36.671806\n",
      "15 time: 0:00:37.804410\n",
      "16 time: 0:00:38.915500\n",
      "17 time: 0:00:40.038458\n",
      "18 time: 0:00:41.159670\n",
      "19 time: 0:00:42.267016\n",
      "20 time: 0:00:43.390532\n",
      "21 time: 0:00:44.503532\n",
      "22 time: 0:00:45.625658\n",
      "23 time: 0:00:46.735228\n",
      "24 time: 0:00:47.861756\n",
      "25 time: 0:00:48.988912\n",
      "26 time: 0:00:50.096279\n",
      "27 time: 0:00:51.226783\n",
      "28 time: 0:00:52.331956\n",
      "29 time: 0:00:53.464119\n",
      "30 time: 0:00:54.574552\n",
      "31 time: 0:00:55.702577\n",
      "32 time: 0:00:56.828222\n",
      "33 time: 0:00:57.939896\n",
      "34 time: 0:00:59.068120\n",
      "35 time: 0:01:00.174272\n",
      "36 time: 0:01:01.302635\n",
      "37 time: 0:01:02.408774\n",
      "38 time: 0:01:03.537799\n",
      "39 time: 0:01:04.647471\n",
      "40 time: 0:01:05.772583\n",
      "41 time: 0:01:06.884676\n",
      "42 time: 0:01:08.002336\n",
      "43 time: 0:01:09.126846\n",
      "44 time: 0:01:10.240578\n",
      "45 time: 0:01:11.378175\n",
      "46 time: 0:01:12.488731\n",
      "47 time: 0:01:13.615756\n",
      "48 time: 0:01:14.719905\n",
      "49 time: 0:01:15.847433\n",
      "50 time: 0:01:16.977160\n",
      "51 time: 0:01:18.080325\n",
      "52 time: 0:01:19.213479\n",
      "53 time: 0:01:20.312464\n",
      "54 time: 0:01:21.437991\n",
      "55 time: 0:01:22.550174\n",
      "56 time: 0:01:23.676701\n",
      "57 time: 0:01:24.780350\n",
      "58 time: 0:01:25.908879\n",
      "59 time: 0:01:27.028081\n",
      "60 time: 0:01:28.127115\n",
      "61 time: 0:01:29.263986\n",
      "62 time: 0:01:30.368404\n",
      "63 time: 0:01:31.491997\n",
      "64 time: 0:01:32.602594\n",
      "65 time: 0:01:33.727615\n",
      "66 time: 0:01:34.832418\n",
      "67 time: 0:01:35.955121\n",
      "68 time: 0:01:37.083843\n",
      "69 time: 0:01:38.218207\n",
      "70 time: 0:01:39.371334\n",
      "71 time: 0:01:40.489398\n",
      "72 time: 0:01:41.646957\n",
      "73 time: 0:01:42.778678\n",
      "74 time: 0:01:43.912711\n",
      "75 time: 0:01:45.038366\n",
      "76 time: 0:01:46.144905\n",
      "77 time: 0:01:47.271589\n",
      "78 time: 0:01:48.388228\n",
      "79 time: 0:01:49.534777\n",
      "80 time: 0:01:50.640451\n",
      "81 time: 0:01:51.771037\n",
      "82 time: 0:01:52.881689\n",
      "83 time: 0:01:54.001817\n",
      "84 time: 0:01:55.118369\n",
      "85 time: 0:01:56.226320\n",
      "86 time: 0:01:57.353910\n",
      "87 time: 0:01:58.462184\n",
      "88 time: 0:01:59.595834\n",
      "89 time: 0:02:00.709903\n",
      "90 time: 0:02:01.837072\n",
      "91 time: 0:02:02.949079\n",
      "92 time: 0:02:04.064184\n",
      "93 time: 0:02:05.194779\n",
      "94 time: 0:02:06.308949\n",
      "95 time: 0:02:07.454573\n",
      "96 time: 0:02:08.570175\n",
      "97 time: 0:02:09.697578\n",
      "98 time: 0:02:10.811359\n",
      "99 time: 0:02:11.923459\n",
      "100 time: 0:02:13.051545\n",
      "101 time: 0:02:14.157835\n",
      "102 time: 0:02:15.297872\n",
      "103 time: 0:02:16.404935\n",
      "104 time: 0:02:17.545477\n",
      "105 time: 0:02:18.664650\n",
      "106 time: 0:02:19.788248\n",
      "107 time: 0:02:20.893331\n",
      "108 time: 0:02:22.021093\n",
      "109 time: 0:02:23.151538\n",
      "110 time: 0:02:24.266688\n",
      "111 time: 0:02:25.419411\n",
      "112 time: 0:02:26.538088\n",
      "113 time: 0:02:27.674626\n",
      "114 time: 0:02:28.797147\n",
      "115 time: 0:02:29.937596\n",
      "116 time: 0:02:31.060991\n",
      "117 time: 0:02:32.211399\n",
      "118 time: 0:02:33.297343\n",
      "119 time: 0:02:34.369825\n",
      "120 time: 0:02:35.440754\n",
      "121 time: 0:02:36.520957\n",
      "122 time: 0:02:37.591944\n",
      "123 time: 0:02:38.656874\n",
      "124 time: 0:02:39.749709\n",
      "125 time: 0:02:40.820118\n",
      "126 time: 0:02:41.900571\n",
      "127 time: 0:02:42.978949\n",
      "128 time: 0:02:44.092048\n",
      "129 time: 0:02:45.167741\n"
     ]
    }
   ],
   "source": [
    "train(epochs = 60000, batch_size = 2, interval = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(len(epochs_checkpoint)):\n",
    "    print(\"epoch: %d  d_loss: %.3f  g_loss: %.3f  psnr: %.3f\"\n",
    "         .format(epochs_checkpoint[epoch],\n",
    "                losses[epoch, 0],\n",
    "                losses[epoch, 1],\n",
    "                psnr[epoch]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_2/Sigmoid:0\", shape=(?, 30, 40, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "D = Discriminator(480, 640, 3)\n",
    "img = Image.open(\"../../images/train/image_1.png\")\n",
    "img = np.array(img)\n",
    "valid = D.discriminate(img)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def depth_to_space():\n",
    "    x = tf.random.normal((16, 64, 64, 12))\n",
    "    y = tf.nn.depth_to_space(x, 2)\n",
    "    print(y.shape) # (16, 128, 128, 3)\n",
    "    \n",
    "depth_to_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_weights(g_weight_name)\n",
    "discriminator.save_weights(d_weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
