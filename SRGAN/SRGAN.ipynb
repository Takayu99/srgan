{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import csv\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "[120 160]\n"
     ]
    }
   ],
   "source": [
    "ratio = 4\n",
    "channels = 3\n",
    "HR_size = np.array([480,640])#\n",
    "LR_size = HR_size // ratio\n",
    "H_h = HR_size[0]\n",
    "H_w = HR_size[1]\n",
    "L_h = LR_size[0]\n",
    "L_w = LR_size[1]\n",
    "print(HR_size[0])\n",
    "print(LR_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "#         self.ratio = ratio\n",
    "#         self.HR_size = HR_size\n",
    "#         self.LR_size = HR_size / ratio\n",
    "#         self.H_h = HR_size[0]\n",
    "#         self.H_w = HR_size[1]\n",
    "#         self.L_h = LR_size[0]\n",
    "#         self.L_h = LR_size[1]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def load_data(self, batch_size = 1):\n",
    "        files = glob.glob(\"../../images/train/*.png\", recursive=True)\n",
    "        batch_images = random.sample(files, batch_size)\n",
    "    \n",
    "        HR_images = []\n",
    "        LR_images = []\n",
    "    \n",
    "        for img_path in batch_images:\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            HR_image = img.resize((H_w, H_h))  #(64, 64)\n",
    "            LR_image = img.resize((L_w, L_h))\n",
    "            HR_image = np.array(HR_image)\n",
    "            #img_hr = (img_hr - 127.5) / 127.5\n",
    "            LR_image = np.array(LR_image)\n",
    "            #img_lr = (img_lr - 127.5) / 127.5\n",
    "\n",
    "#             if not is_testing and np.random.random() < 0.5:\n",
    "#                 img_hr = np.fliplr(img_hr)\n",
    "#                 img_lr = np.fliplr(img_lr)\n",
    "\n",
    "            HR_images.append(HR_image)\n",
    "            LR_images.append(LR_image)\n",
    "        \n",
    "        HR_images = np.array(HR_images) / 127.5 - 1\n",
    "        LR_images = np.array(LR_images) / 127.5 - 1\n",
    "        \n",
    "        return HR_images, LR_images\n",
    "\n",
    "#------------------------------------------------------------------#\n",
    "  \n",
    "#------------------------------------------------------------------#\n",
    "\n",
    "class predDataLoader():          \n",
    "    def load_data(self, batch_size, counter):\n",
    "        random.seed(counter)\n",
    "        np.random.seed(counter)\n",
    "\n",
    "        files = glob.glob(\"../../images/test/*.png\", recursive=True)\n",
    "        batch_images = random.sample(files, batch_size)\n",
    "\n",
    "        imgs_or = []\n",
    "        for img_path in batch_images:\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            img_or = np.array(img)\n",
    "            imgs_or.append(img_or)\n",
    "\n",
    "        imgs_or = np.array(imgs_or) / 127.5 - 1.\n",
    "\n",
    "        return imgs_or\n",
    "    \n",
    "    \n",
    "#------------------------------------------------------------------#\n",
    "  \n",
    "#------------------------------------------------------------------#\n",
    "\n",
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Input shape\n",
    "#         self.channels = 3\n",
    "#         self.lr_height = 288                 # Low resolution height\n",
    "#         self.lr_width = 384                  # Low resolution width\n",
    "#         self.lr_shape = (self.lr_height, self.lr_width, self.channels)\n",
    "#         resLevel = 2 #\n",
    "#         self.hr_height = self.lr_height*resLevel  # High resolution height\n",
    "#         self.hr_width = self.lr_width*resLevel     # High resolution width\n",
    "#         self.hr_shape = (self.hr_height, self.hr_width, self.channels)\n",
    "\n",
    "        #残差ブロックの数\n",
    "        # Number of residual blocks in the generator\n",
    "        self.n_residual_blocks = 16 #\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        #img_hrの特徴量をVGG19で算出する\n",
    "        # We use a pre-trained VGG19 model to extract image features from the high resolution\n",
    "        # and the generated high resolution images and minimize the mse between them\n",
    "        self.VGG = self.build_vgg()\n",
    "        self.VGG.trainable = False\n",
    "        self.VGG.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "        #データはここで読み込まれる\n",
    "        # Configure data loader\n",
    "        #self.dataset_name = 'img_align_celeba'\n",
    "        self.data_loader = DataLoader()\n",
    "        self.pred_data_loader = predDataLoader()\n",
    "\n",
    "        #Dのサイズ\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patchH = int(H_h / 2**4) #\n",
    "        patchW = int(H_w / 2**4) #\n",
    "        self.disc_patch = (patchH, patchW, 1) \n",
    "\n",
    "        #DとGのチャンネル設定\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 60 #gf\n",
    "        self.df = 60 #df\n",
    "        #Dビルドとコンパイル\n",
    "        # Build and compile the discriminator\n",
    "        self.Discriminator = self.build_discriminator()\n",
    "        self.Discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #Gのビルド\n",
    "        # Build the generator\n",
    "        self.Generator = self.build_generator()\n",
    "\n",
    "        # High res. and low res. images\n",
    "        HR_image = Input(shape = (H_h, H_w, channels))\n",
    "        LR_image = Input(shape = (L_h, L_w, channels))\n",
    "\n",
    "        #Gで生成されたhrのimg\n",
    "        # Generate high res. version from low res.\n",
    "        SR_image = self.Generator(LR_image)\n",
    "\n",
    "        #hrのimgの特徴量の算出\n",
    "        # Extract image features of the generated img\n",
    "        SR_features = self.VGG(SR_image)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.Discriminator.trainable = False\n",
    "\n",
    "        #学習モデルコンパイル\n",
    "        # Discriminator determines validity of generated high res. images\n",
    "        validity = self.Discriminator(SR_image)\n",
    "\n",
    "        self.combined = Model([LR_image, HR_image], [validity, SR_features])\n",
    "        self.combined.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1],\n",
    "                              optimizer=optimizer)\n",
    "        \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    def build_vgg(self):\n",
    "        \"\"\"\n",
    "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
    "        third block of the model\n",
    "        \"\"\"\n",
    "        VGG = VGG19(weights=\"imagenet\")\n",
    "        # Set outputs to outputs of last conv. layer in block 3\n",
    "        # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
    "        VGG.outputs = [VGG.layers[9].output]\n",
    "\n",
    "        img = Input(shape = (H_h, H_w, channels))\n",
    "\n",
    "        # Extract image features\n",
    "        img_features = VGG(img)\n",
    "\n",
    "        return Model(img, img_features)\n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    #Generator の実装\n",
    "    def build_generator(self):\n",
    "\n",
    "        #残差ブロックの中身\n",
    "        def residual_block(layer_input, n_filters):\n",
    "            \"\"\"Residual block described in paper\"\"\"\n",
    "            d = Conv2D(n_filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
    "            d = Activation('relu')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Conv2D(n_filters, kernel_size=3, strides=1, padding='same')(d)\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = Add()([d, layer_input])\n",
    "            return d\n",
    "\n",
    "        #解像度を2倍にするUpSampling\n",
    "        def deconv2d(layer_input):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input) #\n",
    "            u = Conv2D(120, kernel_size=3, strides=1, padding='same')(u) #\n",
    "            u = Activation('relu')(u)\n",
    "            return u\n",
    "\n",
    "        # Low resolution image input\n",
    "        img_lr = Input(shape = (L_h, L_w, channels))\n",
    "\n",
    "        # Pre-residual block\n",
    "        c1 = Conv2D(60, kernel_size=9, strides=1, padding='same')(img_lr) #\n",
    "        c1 = Activation('relu')(c1)\n",
    "\n",
    "        # Propogate through residual blocks\n",
    "        r = residual_block(c1, self.gf)\n",
    "        for _ in range(self.n_residual_blocks - 1):\n",
    "            r = residual_block(r, self.gf)\n",
    "\n",
    "        #去の残差ブロックと組み合わせる\n",
    "        # Post-residual block\n",
    "        c2 = Conv2D(60, kernel_size=3, strides=1, padding='same')(r) #\n",
    "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
    "        c2 = Add()([c2, c1])\n",
    "\n",
    "        # Upsampling\n",
    "        n = ratio\n",
    "        while(n % 2 == 0):\n",
    "            c2 = deconv2d(c2)\n",
    "            n = n // 2\n",
    "\n",
    "        # Generate high resolution output\n",
    "        gen_hr = Conv2D(channels, kernel_size=9, strides=1, padding='same', activation='tanh')(c2)\n",
    "\n",
    "        return Model(img_lr, gen_hr)\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    #Discriminator の実装\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        \n",
    "        def d_block(layer_input, filters, strides=1, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        # Input img\n",
    "        d0 = Input(shape = (H_h, H_w, channels))\n",
    "        #畳み込み層、チャンネル数を最終的に16倍に\n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2)\n",
    "        d3 = d_block(d2, self.df*2)\n",
    "        d4 = d_block(d3, self.df*2, strides=2)\n",
    "        d5 = d_block(d4, self.df*4)\n",
    "        d6 = d_block(d5, self.df*4, strides=2)\n",
    "        d7 = d_block(d6, self.df*8)\n",
    "        d8 = d_block(d7, self.df*8, strides=2)\n",
    "        #この時点で画像サイズ1/16\n",
    "        d9 = Dense(self.df*16)(d8)\n",
    "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "        validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "        return Model(d0, validity)\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #学習\n",
    "    def train(self, epochs, batch_size, sample_interval=100):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        psnr_file = open('psnr.csv' , 'w+')\n",
    "        psnr_file.close()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ----------------------\n",
    "            #  Train Discriminator\n",
    "            # ----------------------\n",
    "\n",
    "            # Sample images and their conditioning counterparts\n",
    "            HR_images, LR_images = self.data_loader.load_data(batch_size)\n",
    "\n",
    "            # From low res. image generate high res. version\n",
    "            SR_images = self.Generator.predict(LR_images)\n",
    "\n",
    "            valid = np.ones((batch_size,) + self.disc_patch)\n",
    "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "            #Dのloss\n",
    "            # Train the discriminators (original images = real / generated = Fake)\n",
    "            d_loss_real = self.Discriminator.train_on_batch(HR_images, valid)\n",
    "            d_loss_fake = self.Discriminator.train_on_batch(SR_images, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ------------------\n",
    "            #  Train Generator\n",
    "            # ------------------\n",
    "\n",
    "            # Sample images and their conditioning counterparts\n",
    "           \n",
    "            HR_images, LR_images = self.data_loader.load_data(batch_size)\n",
    "\n",
    "            # The generators want the discriminators to label the generated images as real\n",
    "            valid = np.ones((batch_size,) + self.disc_patch)\n",
    "\n",
    "            # Extract ground truth image features using pre-trained VGG19 model\n",
    "            image_features = self.VGG.predict(HR_images)\n",
    "\n",
    "            # Train the generators\n",
    "            g_loss = self.combined.train_on_batch([LR_images, HR_images], [valid, image_features])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "            # Plot the progress\n",
    "            print (\"%d time: %s\" % (epoch, elapsed_time))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "                self.Generator.save_weights('srg_weight.h5')\n",
    "                \n",
    "                \n",
    "    #------------------------------------------------------------------#\n",
    "    \n",
    "            \n",
    "    def sample_images(self, epoch):\n",
    "        def denormalize(input_data):\n",
    "            input_data = (input_data + 1) * 127.5\n",
    "            return input_data.astype(np.uint8)\n",
    "        os.makedirs('../../images/images/%s' , exist_ok=True)\n",
    "        r, c = 2, 2\n",
    "\n",
    "        HR_images, LR_images = self.data_loader.load_data(batch_size=2)\n",
    "        SR_images = self.Generator.predict(LR_images)\n",
    "\n",
    "        LR_images = denormalize(LR_images)\n",
    "        SR_images = denormalize(SR_images)\n",
    "        HR_images = denormalize(HR_images)\n",
    "\n",
    "        def psnr_calc(img1: np.ndarray, img2: np.ndarray, upscaling=2):\n",
    "            def convert(img):\n",
    "                return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            def extract_y(image: np.ndarray) -> np.ndarray:\n",
    "                if image.ndim == 2:\n",
    "                    return image\n",
    "                image = image.astype(np.int32)\n",
    "                return ((image[:, :, 2] * 65.481 / 255.\n",
    "                          + image[:, :, 1] * 128.553 / 255.\n",
    "                          + image[:, :, 0] * 24.966 / 255.) + 16).astype(np.int32)\n",
    "\n",
    "\n",
    "            def psnr(img1, img2):\n",
    "                mse = np.mean((img1 - img2) ** 2)\n",
    "                if mse == 0:\n",
    "                    return 100\n",
    "                PIXEL_MAX = 255.0\n",
    "                return 10 * math.log10(PIXEL_MAX * PIXEL_MAX / mse)\n",
    "  \n",
    "            img1_conv=convert(img1)\n",
    "            img2_conv=convert(img2)\n",
    "  \n",
    "            # BGR -> YCrCb\n",
    "            # 画像はcv2.imreadで読まれている前提 [0, 255]\n",
    "            y1 = extract_y(img1_conv)\n",
    "            y2 = extract_y(img2_conv)\n",
    "            # 周囲のcropping\n",
    "            # assert y1.shape == y2.shape\n",
    "            h, w = y1.shape\n",
    "            cr = upscaling\n",
    "            cropped_y1 = y1[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "            cropped_y2 = y2[cr:h - cr, cr:w - cr].astype(np.float64)\n",
    "\n",
    "            # psnr\n",
    "            psnr_val = psnr(cropped_y1, cropped_y2)\n",
    "            return psnr_val\n",
    "        \n",
    "        \n",
    "        # Save generated images and the high resolution originals\n",
    "        titles = ['Generated', 'Original']\n",
    "\n",
    "        cv2.imwrite(\"../../images/images/hreal_img_0.png\",HR_images[0])\n",
    "        cv2.imwrite(\"../../images/images/hreal_img_1.png\",HR_images[1])\n",
    "        cv2.imwrite(\"../../images/images/lreal_img_0.png\",LR_images[0])\n",
    "        cv2.imwrite(\"../../images/images/lreal_img_1.png\",LR_images[1])\n",
    "        # size=(480,480)\n",
    "\n",
    "        for i in range(r):\n",
    "            psnr = psnr_calc(HR_images[i],SR_images[i])\n",
    "            print(psnr)\n",
    "            data =[epoch,psnr]\n",
    "            psnr_file = open('psnr.csv' , 'a')\n",
    "            writer = csv.writer(psnr_file, lineterminator='\\n')  \n",
    "            writer.writerow(data)\n",
    "            psnr_file.close()\n",
    "            cv2.imwrite(\"../../images/images/{}_{}img_pred.png\".format(epoch,i),SR_images[i])\n",
    "            \n",
    "            \n",
    "    #------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = SRGAN()\n",
    "    gan.train(epochs=500, batch_size=1, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
